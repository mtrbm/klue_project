{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"vscode":{"interpreter":{"hash":"1201aed7278f566d08684214e947d9aa97ba318061e22672851b23b6bee3a7a3"}},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10170312,"sourceType":"datasetVersion","datasetId":6281066},{"sourceId":10170362,"sourceType":"datasetVersion","datasetId":6281101}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\"모든 참가자의 '제출'을 목표로 합니다\"를 기반으로 하여 만든 klue/roberta를 이용한 베이스라인입니다.\n\n\n\npytorch를 처음 접하시는 분들을 위해 라인마다 아는대로 설명을 써놨으나\n\n\n\n저도 배운지 얼마 안되어서 부족한 면도 있으니 양해부탁드립니다.","metadata":{"id":"Tszu1H5Gn0UB"}},{"cell_type":"markdown","source":"우선 필요한 패키지들을 import합니다. 처음 보실법한 패키지들을 설명드리면\n\n\n\n1. transformers : Huggingface에 등록된 pretrained model/tokenizer를 불러올 수 있는 패키지\n\n2. torch : 머신러닝 패키지\n\n3. tqdm : batch별로 프로세스할 때 진행상황을 바로 보여주는 패키지\n\n\n\n나머지는 아실거라 짐작하고 넘어가겠습니다.","metadata":{"id":"6aV6Cwxan0UC"}},{"cell_type":"code","source":"# from google.colab import drive\n\n# drive.mount('/content/drive')\n\n# import sys\n\n# sys.path.append('/content/drive/MyDrive/project_klue')  # eda_nlp 경로를 추가\n\n# %cd /content/drive/MyDrive/project_klue\n\n# %pwd","metadata":{"id":"I6DidjB6TKEb","colab":{"base_uri":"https://localhost:8080/","height":72},"executionInfo":{"status":"ok","timestamp":1733937664931,"user_tz":-540,"elapsed":21957,"user":{"displayName":"이준희","userId":"15645433344491411224"}},"outputId":"8155432e-2b37-45b7-ceeb-58e05b05ee1b","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T08:46:57.078424Z","iopub.execute_input":"2024-12-12T08:46:57.079032Z","iopub.status.idle":"2024-12-12T08:46:57.317558Z","shell.execute_reply.started":"2024-12-12T08:46:57.078991Z","shell.execute_reply":"2024-12-12T08:46:57.314980Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      3\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"],"ename":"ModuleNotFoundError","evalue":"No module named 'google.colab'","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"# https://dacon.io/en/competitions/official/236037/overview/description\n\n\n\nimport pandas as pd\n\nimport numpy as np\n\nimport torch\n\nimport os\n\nimport random\n\nfrom sklearn.model_selection import train_test_split\n\nfrom transformers import AutoModel, AutoTokenizer\n\nfrom torch.utils.data import Dataset\n\nfrom torch.utils.data import DataLoader\n\nfrom torch import nn\n\nfrom tqdm import tqdm\n\n# from eda import *\n\n\n\n# for graphing\n\nimport seaborn as sns\n\nimport matplotlib.pyplot as plt","metadata":{"id":"qDUc9SIgn0UC","executionInfo":{"status":"ok","timestamp":1733937685171,"user_tz":-540,"elapsed":20243,"user":{"displayName":"이준희","userId":"15645433344491411224"}},"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T11:04:18.472051Z","iopub.execute_input":"2024-12-12T11:04:18.472390Z","iopub.status.idle":"2024-12-12T11:04:29.472977Z","shell.execute_reply.started":"2024-12-12T11:04:18.472359Z","shell.execute_reply":"2024-12-12T11:04:29.472263Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"우선 데이터를 불러와야겠죠?\n\n\n\n예측하는데 ID는 필요없기 때문에 drop 해줬습니다.","metadata":{"id":"0F9Z8tcBn0UD"}},{"cell_type":"code","source":"train_original = pd.read_csv('/kaggle/input/kluedata/train.csv')\n\ntrain_original.drop(columns=['ID'], inplace=True)\n\ntest = pd.read_csv('/kaggle/input/kluedata/test.csv')\n\ntest.drop(columns=['ID'], inplace=True)\n\nsubmission = pd.read_csv('/kaggle/input/kluedata/sample_submission.csv')\n\ntrain_original.shape, test.shape, submission.shape","metadata":{"id":"PTvC_fMpn0UD","executionInfo":{"status":"ok","timestamp":1733937685171,"user_tz":-540,"elapsed":8,"user":{"displayName":"이준희","userId":"15645433344491411224"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7b5bf059-e18e-436c-e562-a5216ce47433","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T11:04:34.853828Z","iopub.execute_input":"2024-12-12T11:04:34.854618Z","iopub.status.idle":"2024-12-12T11:04:34.985607Z","shell.execute_reply.started":"2024-12-12T11:04:34.854586Z","shell.execute_reply":"2024-12-12T11:04:34.984788Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"((16541, 6), (7090, 1), (7090, 2))"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"# import random\n\n# import pickle\n\n# import re\n\n\n\n# wordnet = {}\n\n# with open(\"wordnet.pickle\", \"rb\") as f:\n\n# \twordnet = pickle.load(f)\n\n\n\n\n\n# # 한글만 남기고 나머지는 삭제\n\n# def get_only_hangul(line):\n\n# \tparseText= re.compile('/ ^[ㄱ-ㅎㅏ-ㅣ가-힣]*$/').sub('',line)\n\n\n\n# \treturn parseText\n\n\n\n\n\n\n\n# ########################################################################\n\n# # Synonym replacement\n\n# # Replace n words in the sentence with synonyms from wordnet\n\n# ########################################################################\n\n# def synonym_replacement(words, n):\n\n# \tnew_words = words.copy()\n\n# \trandom_word_list = list(set([word for word in words]))\n\n# \trandom.shuffle(random_word_list)\n\n# \tnum_replaced = 0\n\n# \tfor random_word in random_word_list:\n\n# \t\tsynonyms = get_synonyms(random_word)\n\n# \t\tif len(synonyms) >= 1:\n\n# \t\t\tsynonym = random.choice(list(synonyms))\n\n# \t\t\tnew_words = [synonym if word == random_word else word for word in new_words]\n\n# \t\t\tnum_replaced += 1\n\n# \t\tif num_replaced >= n:\n\n# \t\t\tbreak\n\n\n\n# \tif len(new_words) != 0:\n\n# \t\tsentence = ' '.join(new_words)\n\n# \t\tnew_words = sentence.split(\" \")\n\n\n\n# \telse:\n\n# \t\tnew_words = \"\"\n\n\n\n# \treturn new_words\n\n\n\n\n\n# def get_synonyms(word):\n\n# \tsynomyms = []\n\n\n\n# \ttry:\n\n# \t\tfor syn in wordnet[word]:\n\n# \t\t\tfor s in syn:\n\n# \t\t\t\tsynomyms.append(s)\n\n# \texcept:\n\n# \t\tpass\n\n\n\n# \treturn synomyms\n\n\n\n# ########################################################################\n\n# # Random deletion\n\n# # Randomly delete words from the sentence with probability p\n\n# ########################################################################\n\n# def random_deletion(words, p):\n\n# \tif len(words) == 1:\n\n# \t\treturn words\n\n\n\n# \tnew_words = []\n\n# \tfor word in words:\n\n# \t\tr = random.uniform(0, 1)\n\n# \t\tif r > p:\n\n# \t\t\tnew_words.append(word)\n\n\n\n# \tif len(new_words) == 0:\n\n# \t\trand_int = random.randint(0, len(words)-1)\n\n# \t\treturn [words[rand_int]]\n\n\n\n# \treturn new_words\n\n\n\n# ########################################################################\n\n# # Random swap\n\n# # Randomly swap two words in the sentence n times\n\n# ########################################################################\n\n# def random_swap(words, n):\n\n# \tnew_words = words.copy()\n\n# \tfor _ in range(n):\n\n# \t\tnew_words = swap_word(new_words)\n\n\n\n# \treturn new_words\n\n\n\n# def swap_word(new_words):\n\n# \trandom_idx_1 = random.randint(0, len(new_words)-1)\n\n# \trandom_idx_2 = random_idx_1\n\n# \tcounter = 0\n\n\n\n# \twhile random_idx_2 == random_idx_1:\n\n# \t\trandom_idx_2 = random.randint(0, len(new_words)-1)\n\n# \t\tcounter += 1\n\n# \t\tif counter > 3:\n\n# \t\t\treturn new_words\n\n\n\n# \tnew_words[random_idx_1], new_words[random_idx_2] = new_words[random_idx_2], new_words[random_idx_1]\n\n# \treturn new_words\n\n\n\n# ########################################################################\n\n# # Random insertion\n\n# # Randomly insert n words into the sentence\n\n# ########################################################################\n\n# def random_insertion(words, n):\n\n# \tnew_words = words.copy()\n\n# \tfor _ in range(n):\n\n# \t\tadd_word(new_words)\n\n\n\n# \treturn new_words\n\n\n\n\n\n# def add_word(new_words):\n\n# \tsynonyms = []\n\n# \tcounter = 0\n\n# \twhile len(synonyms) < 1:\n\n# \t\tif len(new_words) >= 1:\n\n# \t\t\trandom_word = new_words[random.randint(0, len(new_words)-1)]\n\n# \t\t\tsynonyms = get_synonyms(random_word)\n\n# \t\t\tcounter += 1\n\n# \t\telse:\n\n# \t\t\trandom_word = \"\"\n\n\n\n# \t\tif counter >= 10:\n\n# \t\t\treturn\n\n\n\n# \trandom_synonym = synonyms[0]\n\n# \trandom_idx = random.randint(0, len(new_words)-1)\n\n# \tnew_words.insert(random_idx, random_synonym)\n\n\n\n\n\n\n\n# def EDA(sentence, alpha_sr=0.1, alpha_ri=0.1, alpha_rs=0.1, p_rd=0.1, num_aug=9):\n\n#     print('EDA******************************************')\n\n#     sentence = get_only_hangul(sentence)\n\n#     words = sentence.split(' ')\n\n#     words = [word for word in words if word != \"\"]\n\n#     num_words = len(words)\n\n#     print('word', '!'*50)\n\n#     print(words)\n\n#     augmented_sentences = []\n\n#     num_new_per_technique = int(num_aug/4) + 1\n\n\n\n#     n_sr = max(1, int(alpha_sr*num_words))\n\n#     n_ri = max(1, int(alpha_ri*num_words))\n\n#     n_rs = max(1, int(alpha_rs*num_words))\n\n\n\n#     # sr\n\n#     for _ in range(num_new_per_technique):\n\n#         print('sr'*10)\n\n#         a_words = synonym_replacement(words, n_sr)\n\n#         print('sr words', a_words)\n\n#         augmented_sentences.append(' '.join(a_words))\n\n\n\n#     # ri\n\n#     for _ in range(num_new_per_technique):\n\n#         print('ri'*10)\n\n\n\n#         a_words = random_insertion(words, n_ri)\n\n#         print('ri words', a_words)\n\n#         augmented_sentences.append(' '.join(a_words))\n\n\n\n#     # rs\n\n#     for _ in range(num_new_per_technique):\n\n#         print('rs'*10)\n\n#         a_words = random_swap(words, n_rs)\n\n#         print('rs words', a_words)\n\n#         augmented_sentences.append(\" \".join(a_words))\n\n\n\n#     # rd\n\n#     for _ in range(num_new_per_technique):\n\n#         print('rd'*10)\n\n#         a_words = random_deletion(words, p_rd)\n\n#         print('rd words', a_words)\n\n#         augmented_sentences.append(\" \".join(a_words))\n\n\n\n#     augmented_sentences = [get_only_hangul(sentence) for sentence in augmented_sentences]\n\n#     print('before shuffle', augmented_sentences)\n\n#     random.shuffle(augmented_sentences)\n\n#     print('after shuffle', augmented_sentences)\n\n\n\n\n\n#     if num_aug >= 1:\n\n#         augmented_sentences = augmented_sentences[:num_aug]\n\n#     else:\n\n#         keep_prob = num_aug / len(augmented_sentences)\n\n#         augmented_sentences = [s for s in augmented_sentences if random.uniform(0, 1) < keep_prob]\n\n\n\n#     augmented_sentences.append(sentence)\n\n#     print('증강 완료!!!!!!!!!!!!!!!!!!!!!!!!', augmented_sentences)\n\n#     return augmented_sentences\n\n\n\nimport random\n\nimport pickle\n\nimport re\n\n\n\nwordnet = {}\n\nwith open(\"/kaggle/input/wordnet/wordnet.pickle\", \"rb\") as f:\n\n\twordnet = pickle.load(f)\n\n\n\n\n\n# 한글만 남기고 나머지는 삭제\n\ndef get_only_hangul(line):\n\n\tparseText= re.compile('/ ^[ㄱ-ㅎㅏ-ㅣ가-힣]*$/').sub('',line)\n\n\n\n\treturn parseText\n\n\n\n\n\n\n\n########################################################################\n\n# Synonym replacement\n\n# Replace n words in the sentence with synonyms from wordnet\n\n########################################################################\n\ndef synonym_replacement(words, n):\n\n\tnew_words = words.copy()\n\n\trandom_word_list = list(set([word for word in words]))\n\n\trandom.shuffle(random_word_list)\n\n\tnum_replaced = 0\n\n\tfor random_word in random_word_list:\n\n\t\tsynonyms = get_synonyms(random_word)\n\n\t\tif len(synonyms) >= 1:\n\n\t\t\tsynonym = random.choice(list(synonyms))\n\n\t\t\tnew_words = [synonym if word == random_word else word for word in new_words]\n\n\t\t\tnum_replaced += 1\n\n\t\tif num_replaced >= n:\n\n\t\t\tbreak\n\n\n\n\tif len(new_words) != 0:\n\n\t\tsentence = ' '.join(new_words)\n\n\t\tnew_words = sentence.split(\" \")\n\n\n\n\telse:\n\n\t\tnew_words = \"\"\n\n\n\n\treturn new_words\n\n\n\n\n\ndef get_synonyms(word):\n\n\tsynomyms = []\n\n\n\n\ttry:\n\n\t\tfor syn in wordnet[word]:\n\n\t\t\tfor s in syn:\n\n\t\t\t\tsynomyms.append(s)\n\n\texcept:\n\n\t\tpass\n\n\n\n\treturn synomyms\n\n\n\n########################################################################\n\n# Random deletion\n\n# Randomly delete words from the sentence with probability p\n\n########################################################################\n\ndef random_deletion(words, p):\n\n\tif len(words) == 1:\n\n\t\treturn words\n\n\n\n\tnew_words = []\n\n\tfor word in words:\n\n\t\tr = random.uniform(0, 1)\n\n\t\tif r > p:\n\n\t\t\tnew_words.append(word)\n\n\n\n\tif len(new_words) == 0:\n\n\t\trand_int = random.randint(0, len(words)-1)\n\n\t\treturn [words[rand_int]]\n\n\n\n\treturn new_words\n\n\n\n########################################################################\n\n# Random swap\n\n# Randomly swap two words in the sentence n times\n\n########################################################################\n\ndef random_swap(words, n):\n\n\tnew_words = words.copy()\n\n\tfor _ in range(n):\n\n\t\tnew_words = swap_word(new_words)\n\n\n\n\treturn new_words\n\n\n\ndef swap_word(new_words):\n\n\trandom_idx_1 = random.randint(0, len(new_words)-1)\n\n\trandom_idx_2 = random_idx_1\n\n\tcounter = 0\n\n\n\n\twhile random_idx_2 == random_idx_1:\n\n\t\trandom_idx_2 = random.randint(0, len(new_words)-1)\n\n\t\tcounter += 1\n\n\t\tif counter > 3:\n\n\t\t\treturn new_words\n\n\n\n\tnew_words[random_idx_1], new_words[random_idx_2] = new_words[random_idx_2], new_words[random_idx_1]\n\n\treturn new_words\n\n\n\n########################################################################\n\n# Random insertion\n\n# Randomly insert n words into the sentence\n\n########################################################################\n\ndef random_insertion(words, n):\n\n\tnew_words = words.copy()\n\n\tfor _ in range(n):\n\n\t\tadd_word(new_words)\n\n\n\n\treturn new_words\n\n\n\n\n\ndef add_word(new_words):\n\n\tsynonyms = []\n\n\tcounter = 0\n\n\twhile len(synonyms) < 1:\n\n\t\tif len(new_words) >= 1:\n\n\t\t\trandom_word = new_words[random.randint(0, len(new_words)-1)]\n\n\t\t\tsynonyms = get_synonyms(random_word)\n\n\t\t\tcounter += 1\n\n\t\telse:\n\n\t\t\trandom_word = \"\"\n\n\n\n\t\tif counter >= 10:\n\n\t\t\treturn\n\n\n\n\trandom_synonym = synonyms[0]\n\n\trandom_idx = random.randint(0, len(new_words)-1)\n\n\tnew_words.insert(random_idx, random_synonym)\n\n\n\n\n\n\n\ndef EDA(sentence, alpha_sr=0.1, alpha_ri=0.1, alpha_rs=0.1, p_rd=0.1, num_aug=9):\n\n\tsentence = get_only_hangul(sentence)\n\n\twords = sentence.split(' ')\n\n\twords = [word for word in words if word != \"\"]\n\n\tnum_words = len(words)\n\n\n\n\taugmented_sentences = []\n\n\tnum_new_per_technique = int(num_aug/4) + 1\n\n\n\n\tn_sr = max(1, int(alpha_sr*num_words))\n\n\tn_ri = max(1, int(alpha_ri*num_words))\n\n\tn_rs = max(1, int(alpha_rs*num_words))\n\n\n\n\t# sr\n\n\tfor _ in range(num_new_per_technique):\n\n\t\ta_words = synonym_replacement(words, n_sr)\n\n\t\taugmented_sentences.append(' '.join(a_words))\n\n\n\n\t# ri\n\n\tfor _ in range(num_new_per_technique):\n\n\t\ta_words = random_insertion(words, n_ri)\n\n\t\taugmented_sentences.append(' '.join(a_words))\n\n\n\n\t# rs\n\n\tfor _ in range(num_new_per_technique):\n\n\t\ta_words = random_swap(words, n_rs)\n\n\t\taugmented_sentences.append(\" \".join(a_words))\n\n\n\n\t# rd\n\n\tfor _ in range(num_new_per_technique):\n\n\t\ta_words = random_deletion(words, p_rd)\n\n\t\taugmented_sentences.append(\" \".join(a_words))\n\n\n\n\taugmented_sentences = [get_only_hangul(sentence) for sentence in augmented_sentences]\n\n\trandom.shuffle(augmented_sentences)\n\n\n\n\tif num_aug >= 1:\n\n\t\taugmented_sentences = augmented_sentences[:num_aug]\n\n\telse:\n\n\t\tkeep_prob = num_aug / len(augmented_sentences)\n\n\t\taugmented_sentences = [s for s in augmented_sentences if random.uniform(0, 1) < keep_prob]\n\n\n\n\taugmented_sentences.append(sentence)\n\n\n\n\treturn augmented_sentences","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-Lvb2RGYfve8","executionInfo":{"status":"ok","timestamp":1733937686084,"user_tz":-540,"elapsed":920,"user":{"displayName":"이준희","userId":"15645433344491411224"}},"outputId":"d269303c-a976-405a-ac2f-05bdd43ef949","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T11:04:35.007816Z","iopub.execute_input":"2024-12-12T11:04:35.008098Z","iopub.status.idle":"2024-12-12T11:04:35.052230Z","shell.execute_reply.started":"2024-12-12T11:04:35.008074Z","shell.execute_reply":"2024-12-12T11:04:35.051617Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"아래 코드는 reproducibility를 위한 설정들이고 데이콘에서 제공한 베이스라인 코드에서 따왔습니다.\n\n\n\n자세한 설명은 : https://tempdev.tistory.com/28\n\n\n\nm1 reproducibility 추가\n\n\n\nCFG안에 key, value에 대해서 설명하자면\n\n1. epochs\n\n    - 총 트레이닝을 몇번 반복할지\n\n    - training set를 처음부터 끝까지 도는걸 몇번할지\n\n2. learning_rate\n\n    - 트레이닝 속도\n\n    - 높으면 optimize 값으로 빨리 접근할 수는 있지만 지나칠 수 있다.\n\n    - 낮으면 optimizer 값으로 느리게 접근하지만 지나치지는 않는다. --> training에 소요되는 시간 증가\n\n3. batch_size\n\n    - 한번에 몇개의 training items를 가지고 neural network의 weight를 조정할 것인가\n\n    - 예를 들어 1000개의 items를 training할 때 batch_size가 32라고 하면 1000개를 32개씩 쪼개서 한번에 32개의 item만을 가지고 training하고 weights를 업데이트하고 다음 32개로 넘어간다. 이때 마지막 그룹은 32개보다 적다.\n\n    - batch_size가 작으면 weights를 자주 업데이트하고 크면 weights를 덜 자주 업데이트 한다 --> batch_size가 작으면 sample size가 작은거랑 비슷하므로 그룹마다 차이가 크다 / batch_size가 크면 sample size가 큰거랑 비슷하므로 그룹마다 차이가 작다.\n\n\n\n\n\n이 코드를 돌린 디바이스가 m1 mac이므로 torch.device('mps')를 썼지만 맥이 아닌 gpu를 쓸때는 'cuda'를 쓰면 된다. gpu가 없다면 'cpu'로 설정하면 되는데 그러면 속도가 많이 느려질 것이다. gpu가 있는지 알아보기 위해서는 torch.cuda.is_available()를 돌려보면 true 아니면 false가 나올 것이다.","metadata":{"id":"Rqo9SK9xn0UD"}},{"cell_type":"code","source":"def seed_everything(seed):\n\n    random.seed(seed)\n\n    os.environ['PYTHONHASHSEED'] = str(seed)\n\n    np.random.seed(seed)\n\n    torch.manual_seed(seed)\n\n    torch.cuda.manual_seed(seed)\n\n    torch.backends.cudnn.deterministic = True\n\n    torch.backends.cudnn.benchmark = True\n\n\n\nCFG = {\n\n    'EPOCHS':20,\n\n    'LEARNING_RATE':1e-5,\n\n    'BATCH_SIZE':32,\n\n    'SEED':41\n\n}\n\n\n\nseed_everything(CFG['SEED']) # Seed 고정\n\ndevice = torch.device('cuda')\n\n\n\n# 데이터 증강\n\n# def export_txt(tokenizer, row, aug, max_length) :\n\n#     text = row[0]\n\n#     print('text 확인', text)\n\n#     if not isinstance(text, str):\n\n#         raise ValueError(f\"text는 문자열이어야 합니다. 현재 타입: {type(text)}\")\n\n\n\n#     if (aug > 0) and (aug <=1) :\n\n#         print('진입 text len', len(text))\n\n#         text = EDA(text, alpha_sr=aug, alpha_ri=aug, alpha_rs=aug, p_rd=aug, num_aug=1)\n\n#         print(f\"after text: {text}, type: {type(text)}, len(text): {len(text)}\")\n\n\n\n#     else :\n\n#         pass\n\n#     inputs = tokenizer(\n\n#         text,\n\n#         return_tensors='pt',\n\n#         truncation=True,\n\n#         max_length=max_length,\n\n#         pad_to_max_length=True,\n\n#         add_special_tokens=True\n\n#         )\n\n#     print('after tokenizer', inputs)\n\n#     input_ids = inputs['input_ids'][0]\n\n#     attention_mask = inputs['attention_mask'][0]\n\n#     return input_ids, attention_mask\n\ndef augment_data(df, text_column, label_column, num_aug=5):\n\n    augmented_data = []\n\n    for _, row in df.iterrows():\n\n        augmented_sentences = EDA(row[text_column], num_aug=num_aug)\n\n        # print('증강',augmented_sentences)\n\n        for sentence in augmented_sentences:\n\n            # print(sentence)\n\n            new_row = {text_column: sentence}  # Initialize new_row with the text_column and sentence\n\n            for label in label_column:  # Iterate through label_columns\n\n                new_row[label] = row[label]  # Add each label column to new_row\n\n            # new_row = {text_column: sentence, label_column: row[label_column]}\n\n\n\n            # new_row = row[label_column].to_dict()  # Convert selected columns to a dictionary\n\n            # new_row[text_column] = sentence        # Add the augmented sentence\n\n            # print(new_row)\n\n            augmented_data.append(new_row)         # Append the new row to the list\n\n    return pd.DataFrame(augmented_data)","metadata":{"id":"MxvLRcKxn0UE","executionInfo":{"status":"ok","timestamp":1733938871269,"user_tz":-540,"elapsed":253,"user":{"displayName":"이준희","userId":"15645433344491411224"}},"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T11:04:35.053681Z","iopub.execute_input":"2024-12-12T11:04:35.053926Z","iopub.status.idle":"2024-12-12T11:04:35.067960Z","shell.execute_reply.started":"2024-12-12T11:04:35.053902Z","shell.execute_reply":"2024-12-12T11:04:35.067106Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"그 다음으로는 train_test_split를 이용해서 train와 val을 나눠줍니다.\n\n\n\n유형(type), 극성(polarity), 시제(tense), 확실성(certainty) 중에서 imbalanced한 label도 있기때문에\n\n\n\nstratify를 추가해주는게 좋다.","metadata":{"id":"YHNCi4A-n0UE"}},{"cell_type":"code","source":"text_column = '문장'\n\nlabel_column = ['유형','극성', '시제', '확실성','label']\n\naugmented_data = augment_data(train_original, text_column, label_column)\n\naugmented_data.shape","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HtvlclliS5_W","executionInfo":{"status":"ok","timestamp":1733938877531,"user_tz":-540,"elapsed":5984,"user":{"displayName":"이준희","userId":"15645433344491411224"}},"outputId":"c1b58116-a3d2-41f8-b379-5e16443d2ad2","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T11:04:35.069023Z","iopub.execute_input":"2024-12-12T11:04:35.069305Z","iopub.status.idle":"2024-12-12T11:04:38.857421Z","shell.execute_reply.started":"2024-12-12T11:04:35.069281Z","shell.execute_reply":"2024-12-12T11:04:38.856528Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"(99246, 6)"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"augmented_data.head()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"DTEl1CzanC1M","executionInfo":{"status":"ok","timestamp":1733938877823,"user_tz":-540,"elapsed":294,"user":{"displayName":"이준희","userId":"15645433344491411224"}},"outputId":"e2e90a41-17f8-4e55-a91f-d03ff6cc8093","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T11:04:38.859890Z","iopub.execute_input":"2024-12-12T11:04:38.860523Z","iopub.status.idle":"2024-12-12T11:04:38.874240Z","shell.execute_reply.started":"2024-12-12T11:04:38.860495Z","shell.execute_reply":"2024-12-12T11:04:38.873447Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                      문장   유형  극성  시제 확실성         label\n0  0.75%포인트 금리 인상은 1994년 28년 이후 만에 처음이다.  사실형  긍정  현재  확실  사실형-긍정-현재-확실\n1  0.75%포인트 금리 인상은 1994년 이후 28년 만에 처음이다.  사실형  긍정  현재  확실  사실형-긍정-현재-확실\n2                     인상은 1994년 이후 처음이다.  사실형  긍정  현재  확실  사실형-긍정-현재-확실\n3  0.75%포인트 금리 인상은 1994년 이후 28년 만에 처음이다.  사실형  긍정  현재  확실  사실형-긍정-현재-확실\n4  0.75%포인트 금리 인상은 1994년 이후 28년 만에 처음이다.  사실형  긍정  현재  확실  사실형-긍정-현재-확실","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>문장</th>\n      <th>유형</th>\n      <th>극성</th>\n      <th>시제</th>\n      <th>확실성</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.75%포인트 금리 인상은 1994년 28년 이후 만에 처음이다.</td>\n      <td>사실형</td>\n      <td>긍정</td>\n      <td>현재</td>\n      <td>확실</td>\n      <td>사실형-긍정-현재-확실</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.75%포인트 금리 인상은 1994년 이후 28년 만에 처음이다.</td>\n      <td>사실형</td>\n      <td>긍정</td>\n      <td>현재</td>\n      <td>확실</td>\n      <td>사실형-긍정-현재-확실</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>인상은 1994년 이후 처음이다.</td>\n      <td>사실형</td>\n      <td>긍정</td>\n      <td>현재</td>\n      <td>확실</td>\n      <td>사실형-긍정-현재-확실</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.75%포인트 금리 인상은 1994년 이후 28년 만에 처음이다.</td>\n      <td>사실형</td>\n      <td>긍정</td>\n      <td>현재</td>\n      <td>확실</td>\n      <td>사실형-긍정-현재-확실</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.75%포인트 금리 인상은 1994년 이후 28년 만에 처음이다.</td>\n      <td>사실형</td>\n      <td>긍정</td>\n      <td>현재</td>\n      <td>확실</td>\n      <td>사실형-긍정-현재-확실</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"train, val, train_target, val_target = train_test_split(augmented_data.drop('label', axis=1), augmented_data['label'], test_size=0.2, random_state=CFG['SEED'])\n\ntrain = train.reset_index(drop=True)\n\nval = val.reset_index(drop=True)\n\ntrain_target = train_target.reset_index(drop=True)\n\nval_target = val_target.reset_index(drop=True)\n\ntrain.shape, val.shape, train_target.shape, val_target.shape","metadata":{"id":"4mIq3sWLn0UE","executionInfo":{"status":"ok","timestamp":1733938877823,"user_tz":-540,"elapsed":7,"user":{"displayName":"이준희","userId":"15645433344491411224"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0716e1eb-4f46-41b6-e209-42432af8deca","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T11:04:38.875467Z","iopub.execute_input":"2024-12-12T11:04:38.875818Z","iopub.status.idle":"2024-12-12T11:04:38.918698Z","shell.execute_reply.started":"2024-12-12T11:04:38.875778Z","shell.execute_reply":"2024-12-12T11:04:38.917896Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"((79396, 5), (19850, 5), (79396,), (19850,))"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"train","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"bnyWhRppjdA1","executionInfo":{"status":"ok","timestamp":1733938878129,"user_tz":-540,"elapsed":311,"user":{"displayName":"이준희","userId":"15645433344491411224"}},"outputId":"1b5a4360-746a-4084-a0b4-c1a8368fd61e","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T11:04:38.919761Z","iopub.execute_input":"2024-12-12T11:04:38.920055Z","iopub.status.idle":"2024-12-12T11:04:38.930727Z","shell.execute_reply.started":"2024-12-12T11:04:38.920021Z","shell.execute_reply":"2024-12-12T11:04:38.929798Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                                                      문장   유형  극성  시제 확실성\n0      당시 청소년의 위해 보장하기 수면권을 대통령령이 정하는 심야시간에 발의된 대한 게임...  사실형  긍정  과거  확실\n1                         낙화생은 옹크려져 누에 같으면서 몸뚱이가 형체가 있다.  사실형  긍정  현재  확실\n2               휴일이면 자동차를 자가 정비하는 모습을 동네 곳곳에서 쉽게 볼 수 있다.  추론형  긍정  현재  확실\n3      그러나 백병전 답 익숙한 지형에 매복해 활을 쏘는 게릴라전에서는 승전 소식이 들리기...  사실형  긍정  과거  확실\n4      횡령 추정액 중 2017∼2019년 사이 사라진 3억4000만원은 지난달 확인됐다....  사실형  긍정  과거  확실\n...                                                  ...  ...  ..  ..  ..\n79391                     한국 정부도 노인 일자리를 만들기 위 위해 노력해왔다.  사실형  긍정  과거  확실\n79392                  그런데 이렇게 맛 맛 좋은 우곡주를 제가 잘 팔지 못했어요.  대화형  부정  과거  확실\n79393        셀트리온이 밝힌 공식적인 블록딜 사유는 ＇투자 기간별 포트폴리오 조정＇이었다.  사실형  긍정  과거  확실\n79394  화장실은 단지 배 속 평안을 간구하는 생리학적 배 공간이 아니라 인류의 평안을 추구...  추론형  긍정  현재  확실\n79395       이스포츠 사업도 있으며 맡고 함께 특히 이 분야는 글로벌을 모두 담당하고 있다.  사실형  긍정  과거  확실\n\n[79396 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>문장</th>\n      <th>유형</th>\n      <th>극성</th>\n      <th>시제</th>\n      <th>확실성</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>당시 청소년의 위해 보장하기 수면권을 대통령령이 정하는 심야시간에 발의된 대한 게임...</td>\n      <td>사실형</td>\n      <td>긍정</td>\n      <td>과거</td>\n      <td>확실</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>낙화생은 옹크려져 누에 같으면서 몸뚱이가 형체가 있다.</td>\n      <td>사실형</td>\n      <td>긍정</td>\n      <td>현재</td>\n      <td>확실</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>휴일이면 자동차를 자가 정비하는 모습을 동네 곳곳에서 쉽게 볼 수 있다.</td>\n      <td>추론형</td>\n      <td>긍정</td>\n      <td>현재</td>\n      <td>확실</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>그러나 백병전 답 익숙한 지형에 매복해 활을 쏘는 게릴라전에서는 승전 소식이 들리기...</td>\n      <td>사실형</td>\n      <td>긍정</td>\n      <td>과거</td>\n      <td>확실</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>횡령 추정액 중 2017∼2019년 사이 사라진 3억4000만원은 지난달 확인됐다....</td>\n      <td>사실형</td>\n      <td>긍정</td>\n      <td>과거</td>\n      <td>확실</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>79391</th>\n      <td>한국 정부도 노인 일자리를 만들기 위 위해 노력해왔다.</td>\n      <td>사실형</td>\n      <td>긍정</td>\n      <td>과거</td>\n      <td>확실</td>\n    </tr>\n    <tr>\n      <th>79392</th>\n      <td>그런데 이렇게 맛 맛 좋은 우곡주를 제가 잘 팔지 못했어요.</td>\n      <td>대화형</td>\n      <td>부정</td>\n      <td>과거</td>\n      <td>확실</td>\n    </tr>\n    <tr>\n      <th>79393</th>\n      <td>셀트리온이 밝힌 공식적인 블록딜 사유는 ＇투자 기간별 포트폴리오 조정＇이었다.</td>\n      <td>사실형</td>\n      <td>긍정</td>\n      <td>과거</td>\n      <td>확실</td>\n    </tr>\n    <tr>\n      <th>79394</th>\n      <td>화장실은 단지 배 속 평안을 간구하는 생리학적 배 공간이 아니라 인류의 평안을 추구...</td>\n      <td>추론형</td>\n      <td>긍정</td>\n      <td>현재</td>\n      <td>확실</td>\n    </tr>\n    <tr>\n      <th>79395</th>\n      <td>이스포츠 사업도 있으며 맡고 함께 특히 이 분야는 글로벌을 모두 담당하고 있다.</td>\n      <td>사실형</td>\n      <td>긍정</td>\n      <td>과거</td>\n      <td>확실</td>\n    </tr>\n  </tbody>\n</table>\n<p>79396 rows × 5 columns</p>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"위에서 언급했듯이 transformers 패키지를 통해서 pretrained된 모델을 불러올 수 있다.\n\n\n\n불러오는 방법은 https://huggingface.co/models 여기서 model 이름을 검색하고\n\n\n\n모델은 AutoModel.from_pretrained()을 통해서, 토크나이저는 AutoTokenizer.from_pretrained()을 통해서\n\n\n\n모델이름을 파라미터로 넣어주면 된다.","metadata":{"id":"DGBfSVvvn0UE"}},{"cell_type":"code","source":"model_nm = 'klue/roberta-small'\n\nbase_model = AutoModel.from_pretrained(model_nm)\n\ntokenizer = AutoTokenizer.from_pretrained(model_nm)","metadata":{"id":"fM3gqk-ln0UE","executionInfo":{"status":"ok","timestamp":1733938878547,"user_tz":-540,"elapsed":422,"user":{"displayName":"이준희","userId":"15645433344491411224"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9fb15c46-bf24-4f41-b69d-a451838e4a0f","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T11:04:38.932507Z","iopub.execute_input":"2024-12-12T11:04:38.932902Z","iopub.status.idle":"2024-12-12T11:05:08.164129Z","shell.execute_reply.started":"2024-12-12T11:04:38.932863Z","shell.execute_reply":"2024-12-12T11:05:08.163227Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/545 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f91ca44032bb4b309deea58273a2d0ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/273M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"375b197ab4324034a149bfd3e1a4aee4"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-small and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/375 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"534b9154c35743618b303b63d84616d2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f45725806f94faaa69a6e38f4c26423"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/752k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"620cca59bca245dab4808b74e1fbad3f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/173 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a36e1601be14de48521a96dda0e729a"}},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"토크나이저의 역할은 문장을 토큰이라고 하는 작은 단위 (더이상 나눌 수 없는 가장 작은 단위)로 나누어주고 pretrained tokenizer에 그 토큰이 어디에 저장되어 있는지 input_ids로 되돌려준다.\n\n\n\n밑 코드는 그 input_ids 길이가 어떤지 histogram으로 그려본 것이다.\n\n\n\n(저도 이 분야는 신생아라 틀린 부분이 있을 수 있습니다.)","metadata":{"id":"5oOacaEon0UF"}},{"cell_type":"code","source":"# tokenizer_len = [len(tokenizer(s)['input_ids']) for s in train['문장']]\n\n# sns.histplot(tokenizer_len)\n\n# plt.show()\n\n\n\n# print(f'log value : {np.mean(tokenizer_len)+3*np.std(tokenizer_len)}')","metadata":{"id":"KEQLLKFwn0UF","executionInfo":{"status":"ok","timestamp":1733938878547,"user_tz":-540,"elapsed":7,"user":{"displayName":"이준희","userId":"15645433344491411224"}},"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T11:05:08.165162Z","iopub.execute_input":"2024-12-12T11:05:08.165638Z","iopub.status.idle":"2024-12-12T11:05:08.169553Z","shell.execute_reply.started":"2024-12-12T11:05:08.165611Z","shell.execute_reply":"2024-12-12T11:05:08.168733Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"따라서, log를 취해주면","metadata":{"id":"AnOcm61Gn0UF"}},{"cell_type":"code","source":"# tokenizer_log = np.log(tokenizer_len)\n\n# sns.histplot(tokenizer_log)\n\n# plt.show()\n\n\n\n# print(f'log value : {np.mean(tokenizer_log)+3*np.std(tokenizer_log)}')\n\n# print(f'original value : {np.exp(np.mean(tokenizer_log)+3*np.std(tokenizer_log))}')","metadata":{"id":"H8zpSwjKn0UF","executionInfo":{"status":"ok","timestamp":1733938878547,"user_tz":-540,"elapsed":6,"user":{"displayName":"이준희","userId":"15645433344491411224"}},"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T11:05:08.170577Z","iopub.execute_input":"2024-12-12T11:05:08.170819Z","iopub.status.idle":"2024-12-12T11:05:08.182398Z","shell.execute_reply.started":"2024-12-12T11:05:08.170795Z","shell.execute_reply":"2024-12-12T11:05:08.181602Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"따라서, 적정선은 90에서 134 사이가 아닐까 생각된다.","metadata":{"id":"gkmCvmd8n0UF"}},{"cell_type":"markdown","source":"위 값은 잠깐 뒤로하고 아래 코드를 위부터 설명하자면,\n\n\n\ntorch.utils.data의 Dataset의 child class인 SentenceTypeDataset을 만들어준다. 이는 pytorch neural network에 내 맘대로\n\nx가 뭔지 y가 뭔지 정한 dataset을 제공하기 위한 클래스이다. 만드는데 꼭 필요한 function은 총 3가지이다.\n\n\n\n_ _ init _ _()\n\n- x랑 y가 뭔지 저장해줘야 한다.\n\n- 이때 이번에는 텍스트 데이터를 다뤄주기때문에 dataframe, tokenizer, labels를 parameter로 넣어줬고 dataframe의 문장을 tokenizer로 토큰화 시킨다음 self.texts에 저장해주고 입력받은 labels는 그대로 self.labels에 저장해줬다.\n\n- batch에 들어가는 입력들은 input size가 다 같아야 한다. 따라서 tokenizer로 나온 값들을 그대로 넣어버리면 오류가 난다. 위 히스토그램에서 볼 수 있듯이 문장마다 다르기 때문. 따라서 위 값(90)으로 tokenizer의 max_length를 정해주고 max_length보다 작은 길이들은 padding으로 채워주고 긴 길이들은 truncation으로 잘라준다. 이때 max_length는 길면 길수록 training time이 늘어난다.\n\n- tokenizer안에 return_tensors의 pt는 tensor로 tokenizer값을 리턴해준다는 뜻이다.\n\n\n\n_ _ len _ _()\n\n- self.texts의 길이는 리턴해줍니다.\n\n\n\n_ _ getitem _ _()\n\n- idx에 해당되는 x와 y를 리턴해줍니다.\n\n- x는 self.texts에서 가져오고 y는 그 텍스트(x)에 해당되는 type, polarity, tense, certainty를 리턴하면 됩니다.\n\n- 나중 코드에서 나오겠지만 미리 설명을 하자면 labels는 train, val set에서만 dictionary형태로 주어진다. 이때 type, polarity, tense, certainty가 key고 해당 레이블에 해당되는 값을 one-hot encoding한게 value다.\n\n- dictionary에 저장된 형태는 list고 pytorch에는 tensor 형태로 넣어줘야하기 때문에 torch.Tensor()로 형태를 바꾸어준다.\n\n- test set의 경우 labels이 주어지지 않기 때문에 똑같은 길이지만 -1로 채워놓은 tensor를 리턴해준다.","metadata":{"id":"ikA_5nSHn0UF"}},{"cell_type":"code","source":"class SentenceTypeDataset(Dataset):\n\n    def __init__(self, dataframe, tokenizer, labels=None):\n\n        texts = dataframe['문장'].values.tolist()\n\n        # print('texts', texts)\n\n        self.texts = [tokenizer(text, padding='max_length', max_length=90, truncation=True, return_tensors='pt') for text in texts]\n\n        self.labels = labels\n\n\n\n    def __len__(self):\n\n        return len(self.texts)\n\n\n\n    def __getitem__(self, idx):\n\n        text = self.texts[idx]\n\n        # print('text********************\\n', text)\n\n        if self.labels is not None:\n\n            type_tmp = self.labels['type'][idx]\n\n            polarity_tmp = self.labels['polarity'][idx]\n\n            tense_tmp = self.labels['tense'][idx]\n\n            certainty_tmp = self.labels['certainty'][idx]\n\n            return text, torch.Tensor(type_tmp), torch.Tensor(polarity_tmp), torch.Tensor(tense_tmp), torch.Tensor(certainty_tmp)\n\n        else:\n\n            return text, torch.Tensor([-1,-1,-1,-1]), torch.Tensor([-1,-1,-1]), torch.Tensor([-1,-1,-1]), torch.Tensor([-1,-1])\n\n\n\n# class SentenceTypeDataset(Dataset):\n\n#     def __init__(self, df, tokenizer, labels, max_length = 512, aug = 1):\n\n#         self.max_length = max_length\n\n#         self.dataset = df.dropna(axis=0)\n\n#         self.dataset['label_0'] =  pd.DataFrame(labels).iloc[:,0]\n\n#         self.dataset['label_1'] =  pd.DataFrame(labels).iloc[:,1]\n\n#         self.dataset['label_2'] =  pd.DataFrame(labels).iloc[:,2]\n\n#         self.dataset['label_3'] =  pd.DataFrame(labels).iloc[:,3]\n\n#         self.dataset = self.dataset.rename(columns = {'문장' : 'document'})\n\n#         # self.dataset['ID'] = self.dataset['ID'].apply(make_id)\n\n#         self.dataset = self.dataset[['document', 'label_0', 'label_1', 'label_2', 'label_3']]\n\n#         self.tokenizer = tokenizer\n\n#         self.aug = aug\n\n#         print('found {} data'.format(len(self.dataset)))\n\n#         print(self.dataset.describe())\n\n\n\n#     def __len__(self):\n\n#         return len(self.dataset)\n\n\n\n#     def __getitem__(self, idx):\n\n#         # row에 문장도 포함해야함... 근데 없어...\n\n#         row = self.dataset.iloc[idx, :].values\n\n#         print('row', row)\n\n#         print(row[1], row[2], row[3], row[4])\n\n#         input_ids, attention_mask = export_txt(self.tokenizer, row, self.aug, self.max_length)\n\n#         print('input_ids', input_ids)\n\n#         print('attention_mask', attention_mask)\n\n#         y0, y1, y2, y3 = row[1], row[2], row[3], row[4]\n\n#         return {\n\n#             'input_ids':  input_ids,\n\n#             'attention_mask': attention_mask,\n\n#             'y0':y0, 'y1':y1, 'y2':y2, 'y3':y3\n\n#         }\n\n\n\n# class SentenceTypeDataset(Dataset):\n\n#     def __init__(self, texts, tokenizer, labels, max_len):\n\n#         self.texts = texts['문장'].tolist()  # Access the '문장' column and convert it to a list\n\n#         self.labels = labels\n\n#         self.tokenizer = tokenizer\n\n#         self.max_len = max_len\n\n\n\n#     def __len__(self):\n\n#         return len(self.texts)\n\n\n\n#     def __getitem__(self, idx):\n\n#         text = self.texts[idx]\n\n#         # Get labels based on 'idx' instead of accessing label dict directly.\n\n#         type_label = self.labels['type'][idx]\n\n#         polarity_label = self.labels['polarity'][idx]\n\n#         tense_label = self.labels['tense'][idx]\n\n#         certainty_label = self.labels['certainty'][idx]\n\n#         assert len(self.labels['type']) == len(self.labels['polarity']) == len(self.labels['tense']) == len(self.labels['certainty']), \"라벨 길이가 다릅니다.\"\n\n\n\n#         encoding = self.tokenizer(\n\n#             text,\n\n#             max_length=self.max_len,\n\n#             padding=\"max_length\",\n\n#             truncation=True,\n\n#             return_tensors=\"pt\",\n\n#         )\n\n#         return {\n\n#             \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n\n#             \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n\n#             \"label\": torch.tensor([type_label, polarity_label, tense_label, certainty_label], dtype=torch.long)\n\n#             }\n","metadata":{"id":"Dm6gWhsAn0UF","executionInfo":{"status":"ok","timestamp":1733938878547,"user_tz":-540,"elapsed":6,"user":{"displayName":"이준희","userId":"15645433344491411224"}},"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T11:05:08.185969Z","iopub.execute_input":"2024-12-12T11:05:08.186244Z","iopub.status.idle":"2024-12-12T11:05:08.196892Z","shell.execute_reply.started":"2024-12-12T11:05:08.186221Z","shell.execute_reply":"2024-12-12T11:05:08.196108Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"다음으로는 Classifier class를 만드는 것이다.\n\n\n\n\\__init__()\n\n- 우선 nn.Module의 child class이기 때문에 \\__init__() 안에 super().\\__init__()을 불러주고 base_model을 통해서 받을 pretrained_model을 self.klue에 저장한다.\n\n이때 klue의 output features는 768이다. 확인방법은 base_model을 셀에 쳐보면 된다. (더 쉬운 방법이 있으면 알려주세요)\n\n\n\n- transfer learning의 기본적인 방법은 중간에 hidden layer는 pretrained_model의 것을 이용하고 output layer를 내가 원하는 방향으로 만들어서 training 하는 것이다. 따라서, self.fc1, self.type_clf, self.softmax 등등 다양한 레이어들을 추가해줬다. 이때 self.fc1에는 nn.Linear(768, 32)를 저장해줬는데, 이는 in_feature로 768, out_feature로는 32를 내보낸다는 뜻이다. 일반적으로 알고 있는 dense layer의 역할을 한다. 그 다음으로는 self.relu에 nn.ReLU()를 저장해서 activation function으로 사용해줬다. 그 다음으로는 multilabel classification 문제이기 때문에 각 label마다 nn.Linear(32, # of types)으로 레이어를 만들어줬다. 이때 # of types만큼의 out_feature가 필요한 이유는 types들을 one-hot encoding을 해줬기 때문이다. 그 다음으로는 classification에 많이 사용되는 nn.Softmax(dim=1)을 넣어줬다. softmax에서 나온 값들의 합은 1로써 어느 type에 해당되는지 확률들을 리턴해준다. 이때 합해져야되는 값들이 dim=1에 있기때문에 dim=1이라는 파라미터를 넣어주었다.\n\n\n\n\\__forward__()\n\n- 그 다음으로 꼭 작성해줘야 하는 function은 forward다. (backward는 필요없음) 여기서는 위에서 작성한 레이어들을 어느 순서로 지나칠지 순서를 정해주는 단계이다. 우선, pretrained_model을 지나고 나온 output을 fc1과 relu에 넘겨주고 그 다음으로는 각 label의 clf-softmax 페어를 지나쳐준다. 그리고 나온 4개의 output을 리턴해주면 된다.\n\n- multilabel이기 때문에 4개의 값을 리턴해주는거지 단순하게 binary 또는 multiclassification이면 보통 1개의 output만을 리턴해주면 된다.\n\n- 아래 코드에 써있듯이 input_ids는 토큰에 해당되는 ids들, attention_mask는 어느 토큰에 집중해야되는지 알려주는 역할을 한다. 이는 왜 필요하나 하면 padding 단계에서 추가된 padding token에 대한 접근을 막기위해 사용된다.","metadata":{"id":"_ydzoI20n0UF"}},{"cell_type":"code","source":"class SentenceClassifier(nn.Module):\n\n    def __init__(self, base_model):\n\n        super().__init__()\n\n        self.klue = base_model # from transformers package\n\n\n\n        self.fc1 = nn.Linear(self.klue.config.hidden_size, 32)\n\n        self.layernorm = nn.LayerNorm(32)\n\n        self.dropout = nn.Dropout(p = 0.1)\n\n        self.relu = nn.ReLU()\n\n        self.type_clf = nn.Linear(32,4)\n\n        self.polarity_clf = nn.Linear(32,3)\n\n        self.tense_clf = nn.Linear(32,3)\n\n        self.certainty_clf = nn.Linear(32,2)\n\n        self.softmax = nn.Softmax(dim=1)\n\n\n\n    def forward(self, input_ids, attention_mask):\n\n        # input_ids : token's id / attention_mask : make a model to focus on which token\n\n        klue_out = self.klue(input_ids= input_ids, attention_mask = attention_mask)[0][:,0]\n\n\n\n        x = self.fc1(klue_out)\n\n        # print('x*************************', x)\n\n        x = self.layernorm(x)\n\n        x = self.dropout(x)\n\n        x = self.relu(x)\n\n\n\n        type_output = self.type_clf(x)\n\n        type_output = self.softmax(type_output)\n\n        polarity_output = self.polarity_clf(x)\n\n        polarity_output = self.softmax(polarity_output)\n\n        tense_output = self.tense_clf(x)\n\n        tense_output = self.softmax(tense_output)\n\n        certainty_output = self.certainty_clf(x)\n\n        certainty_output = self.softmax(certainty_output)\n\n\n\n        return type_output, polarity_output, tense_output, certainty_output","metadata":{"id":"FjU_XG1Mn0UG","executionInfo":{"status":"ok","timestamp":1733938878547,"user_tz":-540,"elapsed":6,"user":{"displayName":"이준희","userId":"15645433344491411224"}},"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T11:05:08.197820Z","iopub.execute_input":"2024-12-12T11:05:08.198162Z","iopub.status.idle":"2024-12-12T11:05:08.211502Z","shell.execute_reply.started":"2024-12-12T11:05:08.198137Z","shell.execute_reply":"2024-12-12T11:05:08.210777Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"다음으로는! training 단계이다.\n\n\n\n우선 val_loss를 기준으로 early_stop을 할건지 말건지 정하기 때문에 best_val_loss를 설정해주었고, crossentropyloss를 이용할건데 작아질수록 좋은 값이기 때문에 최초값은 높은 값으로 설정해주었다.\n\n\n\n그 다음으로는 criterion인데 이는 loss function이다. 4개의 다른 label들이 있기 때문에 dictionary에 4개를 넣어주었다. 나중 단계에서 criterion에 있는 CrossEntropyLoss를 통해서 true값과 pred값의 차이를 구하고 어떤 방향으로 weights를 조정해야되는지 정한다.\n\n\n\noptimizer는 어떤 방식으로 최적화를 한걸지 정해주는 변수인데, 일반적으로 많이 쓰이는 Adam을 써줬다. Adam 안에는 모델의 파라미터(model.parameters())와 learning_rate를 넣어주었다. 위에서 언급했듯이 이때 learning_rate가 큰지 작은지에 따라 training 속도가 결정난다. 그 다음으로는 모델을 gpu로 보내주었다. 이 코드가 있어야 gpu를 사용해서 training 한다.\n\n- mac m칩 유저의 경우 “PYTORCH_ENABLE_MPS_FALLBACK=1”를 설정해줘야 mps가 안되는 코드는 cpu로 계산을 해준다. (2022/12/16 cumsum은 mps로 계산이 안됨)\n\n\n\n그리고 주어진 epochs만큰 for loop을 돌리는데 그 밑에 있는 total_acc_train은 total_f1_train으로 바뀌어야 맞다. 이 부분은 중간에 f1 계산하는 코드 넣는거를 까먹고 못하고 코드를 그대로 돌려서 남은 것이니 만약 이 코드 그대로 돌린다고 하면 바꾸어주길 바란다. 그 밑에 total_loss_train은 epoch별로 loss 값이 어땠는지 기록해주기 위해 만든 변수다.\n\n\n\n그 다음으로는 model.train()이 있는데 이는 model을 training 모드로 만들어주는거다. 이렇게 해야 weight들이 업데이트된다. 이와 반대로 나중에 val이나 test set을 모델에 넘겨줄때는 model.eval()을 불러줘야한다. 이래야 weights들이 업데이트 되지 않는다.\n\n\n\n그 다음으로는 train_dataloader를 for loop으로 돌려주는데 뒤에 나오겠지만 dataloader는 지정해준 batch_size만큼 item의 x와 y를 넘겨준다. 이때 쓰이는 것이 위에서 만들어준 SentenceTypeDataset의 getitem()이다. 따라서, 5개의 변수 (train_input, type_label, polarity_label, tense_label, certainty_label)로 받아야한다. 그 다음으로는 train_input에 있는 attention_mask와 input_ids와 label들을 device로 넘겨준다.\n\n\n\n그리고 training을 시작하기 전에 optimizer.grad()를 설정해줘서 매 epoch마다 전에 썼던 값들을 기억하는 것이 아니라 0 베이스에서 시작하게 해준다. epoch를 통한 값들의 정확한 업데이트를 위해서는 꼭 필요한 코드다.\n\n\n\n그리고 나서 model에 input_ids와 attention_mask를 넣어서 얻은 4개의 값들을 저장해준다. 이때 이 값들은 각 label마다 one-hot encoding된 컬럼에 해당될 확률들이다. 바로 다음에 이 값들은 criterion에 있는 CrossEntropyLoss()로 들어가서 실제와 얼마나 유사한지 계산되고 그 계산된 값을 total_loss_train에 저장해준다.\n\n\n\n그 다음으로는 계산된 loss 값을 바탕으로 backpropagation(loss.backward()과 optimizer.step()을 통해서)을 진행하여 weights들을 업데이트해준다.\n\n\n\n이렇게 training data를 다 거쳤다면 그 다음은 validation data 차례다. 우선 with torch.no_grad()과 model.eval()을 불러주어서 weights들을 업데이트하는게 아니라는 것을 선언해준다. 그 후에는 training data에서 했던 방식이랑 다 같지만 optimizer.zero_grad(), loss.backward(), optimier.step()만 빠진다. weights들을 업데이트하지 않기 때문.\n\n\n\n그 다음으로는 지금까지 저장한 loss와 metric을 프린트해주고, val_loss가 좋아졌는지 여부에 따라서 모델을 저장할 것인지 early stop 할 것인지 정해준다.","metadata":{"id":"2W2ly2J_n0UG"}},{"cell_type":"code","source":"from sklearn.metrics import f1_score\n\nimport numpy as np\n\nimport torch\n\n\n\ndef sentence_train(model, train_dataloader, val_dataloader, learning_rate, epochs, model_nm):\n\n    best_val_loss = 99999999999999  # setting max (act as infinity)\n\n    early_stopping_threshold_count = 0\n\n\n\n    criterion = {\n\n        'type': nn.CrossEntropyLoss().to(device),\n\n        'polarity': nn.CrossEntropyLoss().to(device),\n\n        'tense': nn.CrossEntropyLoss().to(device),\n\n        'certainty': nn.CrossEntropyLoss().to(device)\n\n    }\n\n\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n\n    model = model.to(device)\n\n\n\n    for epoch in range(epochs):\n\n        total_f1_train = 0  # F1 score for training set\n\n        total_loss_train = 0\n\n\n\n        model.train()  # sets into the training mode\n\n\n\n        all_true_labels = []\n\n        all_pred_labels = []\n\n\n\n        for train_input, type_label, polarity_label, tense_label, certainty_label in tqdm(train_dataloader):\n\n            attention_mask = train_input['attention_mask'].to(device)\n\n            input_ids = train_input['input_ids'].squeeze(1).to(device)\n\n            type_label = type_label.to(device)\n\n            polarity_label = polarity_label.to(device)\n\n            tense_label = tense_label.to(device)\n\n            certainty_label = certainty_label.to(device)\n\n            optimizer.zero_grad()  # 가중치를 업데이트할 때 사용할 기울기를 초기화\n\n\n\n            type_output, polarity_output, tense_output, certainty_output = model(input_ids, attention_mask)  # from the forward function\n\n            # print('output***********************************************', type_output, polarity_output, tense_output, certainty_output)\n\n            loss = 0.25 * criterion['type'](type_output, type_label) + 0.25 * criterion['polarity'](polarity_output, polarity_label) + 0.25 * criterion['tense'](tense_output, tense_label) + 0.25 * criterion['certainty'](certainty_output, certainty_label)\n\n            total_loss_train += loss.item()\n\n\n\n            loss.backward()\n\n            optimizer.step()\n\n\n\n            # Collect true labels and predicted labels for F1 score calculation\n\n            all_true_labels.append(type_label.cpu().numpy())  # True labels\n\n            all_pred_labels.append(torch.argmax(type_output, dim=1).cpu().numpy())  # Predicted labels\n\n\n\n        # Flatten the list of true and predicted labels\n\n\n\n        all_true_labels = np.argmax(np.concatenate(all_true_labels), axis=1) if all_true_labels[0].ndim > 1 else np.concatenate(all_true_labels)\n\n        all_pred_labels = np.argmax(np.concatenate(all_pred_labels), axis=1) if all_pred_labels[0].ndim > 1 else np.concatenate(all_pred_labels)\n\n\n\n        print(all_true_labels)\n\n        print(all_pred_labels)\n\n        # Compute F1 score for training\n\n        total_f1_train = f1_score(all_true_labels, all_pred_labels, average='weighted')  # 'weighted' for multiclass\n\n\n\n        with torch.no_grad():  # since we should not change gradient for validation\n\n            total_f1_val = 0  # F1 score for validation set\n\n            total_loss_val = 0\n\n\n\n            model.eval()  # deactivate training\n\n\n\n            all_true_val_labels = []\n\n            all_pred_val_labels = []\n\n\n\n            for val_input, vtype_label, vpolarity_label, vtense_label, vcertainty_label in tqdm(val_dataloader):\n\n                attention_mask = val_input['attention_mask'].to(device)\n\n                input_ids = val_input['input_ids'].squeeze(1).to(device)\n\n\n\n                vtype_label = vtype_label.to(device)\n\n                vpolarity_label = vpolarity_label.to(device)\n\n                vtense_label = vtense_label.to(device)\n\n                vcertainty_label = vcertainty_label.to(device)\n\n\n\n                vtype_output, vpolarity_output, vtense_output, vcertainty_output = model(input_ids, attention_mask)  # from the forward function\n\n\n\n                loss = 0.25 * criterion['type'](vtype_output, vtype_label) + 0.25 * criterion['polarity'](vpolarity_output, vpolarity_label) + 0.25 * criterion['tense'](vtense_output, vtense_label) + 0.25 * criterion['certainty'](vcertainty_output, vcertainty_label)\n\n\n\n                total_loss_val += loss.item()\n\n\n\n                # Collect true labels and predicted labels for F1 score calculation\n\n                all_true_val_labels.append(vtype_label.cpu().numpy())  # True labels\n\n                all_pred_val_labels.append(torch.argmax(vtype_output, dim=1).cpu().numpy())  # Predicted labels\n\n\n\n            # Flatten the list of true and predicted labels\n\n            all_true_val_labels = np.argmax(np.concatenate(all_true_val_labels), axis=1) if all_true_val_labels[0].ndim > 1 else np.concatenate(all_true_val_labels)\n\n            all_pred_val_labels = np.argmax(np.concatenate(all_pred_val_labels), axis=1) if all_pred_val_labels[0].ndim > 1 else np.concatenate(all_pred_val_labels)\n\n\n\n            print(all_true_val_labels)\n\n            print(all_pred_val_labels)\n\n            # Compute F1 score for validation\n\n            total_f1_val = f1_score(all_true_val_labels, all_pred_val_labels, average='weighted')  # 'weighted' for multiclass\n\n\n\n            os.makedirs(\"model\", exist_ok=True)\n\n\n\n            print(f'Epochs: {epoch + 1} '\n\n                  f'| Train Loss: {total_loss_train / len(train_dataloader): .3f} '\n\n                  f'| Train F1 Score: {total_f1_train: .3f} '\n\n                  f'| Val Loss: {total_loss_val / len(val_dataloader): .3f} '\n\n                  f'| Val F1 Score: {total_f1_val: .3f}')\n\n\n\n            if best_val_loss > total_loss_val:\n\n                best_val_loss = total_loss_val  # saving only the best one\n\n                torch.save(model, f\"model/{model_nm}.pt\")\n\n                print(\"Saved model\")\n\n                early_stopping_threshold_count = 0\n\n            else:\n\n                early_stopping_threshold_count += 1  # checking how many epochs have passed that val_loss didn't increase\n\n\n\n            if early_stopping_threshold_count >= 3:  # ==> patience=1\n\n                print(\"Early stopping\")\n\n                break\n","metadata":{"id":"uChaWMcLn0UG","executionInfo":{"status":"ok","timestamp":1733938878547,"user_tz":-540,"elapsed":6,"user":{"displayName":"이준희","userId":"15645433344491411224"}},"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T11:10:08.974256Z","iopub.execute_input":"2024-12-12T11:10:08.974560Z","iopub.status.idle":"2024-12-12T11:10:08.991320Z","shell.execute_reply.started":"2024-12-12T11:10:08.974535Z","shell.execute_reply":"2024-12-12T11:10:08.990502Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"필요한 class, function들은 다 적었으니 이제 dataset들을 준비할 차례다.\n\n\n\n우선 train에서 label을 제외한 나머지 컬럼들만 킵해주고 그중에서도 유형,극성,시제,확실성을 pd.get_dummies로 one-hot encoding해준다.","metadata":{"id":"h1B3zH4Cn0UG"}},{"cell_type":"code","source":"print('before shape', train.shape)\n\ntrain_tmp = train[['문장', '유형', '극성', '시제', '확실성']]\n\ntrain_tmp = pd.get_dummies(train_tmp, columns=['유형', '극성', '시제', '확실성'])\n\nprint('train_tmp', train_tmp.head())\n\n\n\nprint('after shape', train_tmp.shape)","metadata":{"id":"2cp8CqOPn0UG","executionInfo":{"status":"ok","timestamp":1733938878547,"user_tz":-540,"elapsed":6,"user":{"displayName":"이준희","userId":"15645433344491411224"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7a318ab5-075c-4c1f-b839-a2eee757fd9d","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T11:10:12.396557Z","iopub.execute_input":"2024-12-12T11:10:12.397150Z","iopub.status.idle":"2024-12-12T11:10:12.464602Z","shell.execute_reply.started":"2024-12-12T11:10:12.397116Z","shell.execute_reply":"2024-12-12T11:10:12.463754Z"}},"outputs":[{"name":"stdout","text":"before shape (79396, 5)\ntrain_tmp                                                   문장  유형_대화형  유형_사실형  유형_예측형  \\\n0  당시 청소년의 위해 보장하기 수면권을 대통령령이 정하는 심야시간에 발의된 대한 게임...   False    True   False   \n1                     낙화생은 옹크려져 누에 같으면서 몸뚱이가 형체가 있다.   False    True   False   \n2           휴일이면 자동차를 자가 정비하는 모습을 동네 곳곳에서 쉽게 볼 수 있다.   False   False   False   \n3  그러나 백병전 답 익숙한 지형에 매복해 활을 쏘는 게릴라전에서는 승전 소식이 들리기...   False    True   False   \n4  횡령 추정액 중 2017∼2019년 사이 사라진 3억4000만원은 지난달 확인됐다....   False    True   False   \n\n   유형_추론형  극성_긍정  극성_미정  극성_부정  시제_과거  시제_미래  시제_현재  확실성_불확실  확실성_확실  \n0   False   True  False  False   True  False  False    False    True  \n1   False   True  False  False  False  False   True    False    True  \n2    True   True  False  False  False  False   True    False    True  \n3   False   True  False  False   True  False  False    False    True  \n4   False   True  False  False   True  False  False    False    True  \nafter shape (79396, 13)\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"그 다음으로는 각 label별로 뽑아서 train_labels에 dictionary형태로 저장해준다.","metadata":{"id":"zdQx6etAn0UG"}},{"cell_type":"code","source":"train_type = train_tmp.iloc[:,1:5].values.tolist()\n\ntrain_polarity = train_tmp.iloc[:,5:8].values.tolist()\n\ntrain_tense = train_tmp.iloc[:,8:11].values.tolist()\n\ntrain_certainty = train_tmp.iloc[:,11:13].values.tolist()\n\n\n\ntrain_labels = {\n\n    'type': train_type,\n\n    'polarity': train_polarity,\n\n    'tense': train_tense,\n\n    'certainty': train_certainty\n\n}\n\npd.DataFrame(train_labels)","metadata":{"id":"nePqb56pn0UG","executionInfo":{"status":"ok","timestamp":1733938880574,"user_tz":-540,"elapsed":2032,"user":{"displayName":"이준희","userId":"15645433344491411224"}},"colab":{"base_uri":"https://localhost:8080/","height":424},"outputId":"66ca24c0-51bf-4258-e005-62cb31b30228","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T11:10:18.377847Z","iopub.execute_input":"2024-12-12T11:10:18.378789Z","iopub.status.idle":"2024-12-12T11:10:19.059731Z","shell.execute_reply.started":"2024-12-12T11:10:18.378751Z","shell.execute_reply":"2024-12-12T11:10:19.058898Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"                              type              polarity  \\\n0      [False, True, False, False]  [True, False, False]   \n1      [False, True, False, False]  [True, False, False]   \n2      [False, False, False, True]  [True, False, False]   \n3      [False, True, False, False]  [True, False, False]   \n4      [False, True, False, False]  [True, False, False]   \n...                            ...                   ...   \n79391  [False, True, False, False]  [True, False, False]   \n79392  [True, False, False, False]  [False, False, True]   \n79393  [False, True, False, False]  [True, False, False]   \n79394  [False, False, False, True]  [True, False, False]   \n79395  [False, True, False, False]  [True, False, False]   \n\n                      tense      certainty  \n0      [True, False, False]  [False, True]  \n1      [False, False, True]  [False, True]  \n2      [False, False, True]  [False, True]  \n3      [True, False, False]  [False, True]  \n4      [True, False, False]  [False, True]  \n...                     ...            ...  \n79391  [True, False, False]  [False, True]  \n79392  [True, False, False]  [False, True]  \n79393  [True, False, False]  [False, True]  \n79394  [False, False, True]  [False, True]  \n79395  [True, False, False]  [False, True]  \n\n[79396 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>type</th>\n      <th>polarity</th>\n      <th>tense</th>\n      <th>certainty</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[False, True, False, False]</td>\n      <td>[True, False, False]</td>\n      <td>[True, False, False]</td>\n      <td>[False, True]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[False, True, False, False]</td>\n      <td>[True, False, False]</td>\n      <td>[False, False, True]</td>\n      <td>[False, True]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[False, False, False, True]</td>\n      <td>[True, False, False]</td>\n      <td>[False, False, True]</td>\n      <td>[False, True]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[False, True, False, False]</td>\n      <td>[True, False, False]</td>\n      <td>[True, False, False]</td>\n      <td>[False, True]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[False, True, False, False]</td>\n      <td>[True, False, False]</td>\n      <td>[True, False, False]</td>\n      <td>[False, True]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>79391</th>\n      <td>[False, True, False, False]</td>\n      <td>[True, False, False]</td>\n      <td>[True, False, False]</td>\n      <td>[False, True]</td>\n    </tr>\n    <tr>\n      <th>79392</th>\n      <td>[True, False, False, False]</td>\n      <td>[False, False, True]</td>\n      <td>[True, False, False]</td>\n      <td>[False, True]</td>\n    </tr>\n    <tr>\n      <th>79393</th>\n      <td>[False, True, False, False]</td>\n      <td>[True, False, False]</td>\n      <td>[True, False, False]</td>\n      <td>[False, True]</td>\n    </tr>\n    <tr>\n      <th>79394</th>\n      <td>[False, False, False, True]</td>\n      <td>[True, False, False]</td>\n      <td>[False, False, True]</td>\n      <td>[False, True]</td>\n    </tr>\n    <tr>\n      <th>79395</th>\n      <td>[False, True, False, False]</td>\n      <td>[True, False, False]</td>\n      <td>[True, False, False]</td>\n      <td>[False, True]</td>\n    </tr>\n  </tbody>\n</table>\n<p>79396 rows × 4 columns</p>\n</div>"},"metadata":{}}],"execution_count":20},{"cell_type":"markdown","source":"똑같은 방식으로 validation data도 만든다.","metadata":{"id":"ZXLFnQfqn0UG"}},{"cell_type":"code","source":"val_tmp = val[['문장', '유형', '극성', '시제', '확실성']]\n\nval_tmp = pd.get_dummies(val_tmp, columns=['유형', '극성', '시제', '확실성'])\n\n# print('val_tmp', val_tmp.head())\n\nval_type = val_tmp.iloc[:,1:5].values.tolist()\n\nval_polarity = val_tmp.iloc[:,5:8].values.tolist()\n\nval_tense = val_tmp.iloc[:,8:11].values.tolist()\n\nval_certainty = val_tmp.iloc[:,11:13].values.tolist()\n\nval_labels = {\n\n    'type': val_type,\n\n    'polarity': val_polarity,\n\n    'tense': val_tense,\n\n    'certainty': val_certainty\n\n}\n\npd.DataFrame(val_labels)","metadata":{"id":"Ii91MruAn0UH","executionInfo":{"status":"ok","timestamp":1733938880575,"user_tz":-540,"elapsed":10,"user":{"displayName":"이준희","userId":"15645433344491411224"}},"colab":{"base_uri":"https://localhost:8080/","height":424},"outputId":"e6fd36eb-d403-48b1-a687-eb44b4e657ad","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T11:10:23.081196Z","iopub.execute_input":"2024-12-12T11:10:23.081500Z","iopub.status.idle":"2024-12-12T11:10:23.148646Z","shell.execute_reply.started":"2024-12-12T11:10:23.081476Z","shell.execute_reply":"2024-12-12T11:10:23.147496Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"                              type              polarity  \\\n0      [False, True, False, False]  [True, False, False]   \n1      [False, True, False, False]  [True, False, False]   \n2      [False, True, False, False]  [True, False, False]   \n3      [False, True, False, False]  [True, False, False]   \n4      [False, True, False, False]  [True, False, False]   \n...                            ...                   ...   \n19845  [False, True, False, False]  [True, False, False]   \n19846  [False, True, False, False]  [True, False, False]   \n19847  [False, True, False, False]  [True, False, False]   \n19848  [False, True, False, False]  [True, False, False]   \n19849  [False, False, True, False]  [True, False, False]   \n\n                      tense      certainty  \n0      [False, False, True]  [False, True]  \n1      [True, False, False]  [False, True]  \n2      [False, False, True]  [False, True]  \n3      [True, False, False]  [False, True]  \n4      [False, True, False]  [False, True]  \n...                     ...            ...  \n19845  [True, False, False]  [False, True]  \n19846  [False, False, True]  [False, True]  \n19847  [False, False, True]  [False, True]  \n19848  [True, False, False]  [False, True]  \n19849  [False, True, False]  [False, True]  \n\n[19850 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>type</th>\n      <th>polarity</th>\n      <th>tense</th>\n      <th>certainty</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[False, True, False, False]</td>\n      <td>[True, False, False]</td>\n      <td>[False, False, True]</td>\n      <td>[False, True]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[False, True, False, False]</td>\n      <td>[True, False, False]</td>\n      <td>[True, False, False]</td>\n      <td>[False, True]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[False, True, False, False]</td>\n      <td>[True, False, False]</td>\n      <td>[False, False, True]</td>\n      <td>[False, True]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[False, True, False, False]</td>\n      <td>[True, False, False]</td>\n      <td>[True, False, False]</td>\n      <td>[False, True]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[False, True, False, False]</td>\n      <td>[True, False, False]</td>\n      <td>[False, True, False]</td>\n      <td>[False, True]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>19845</th>\n      <td>[False, True, False, False]</td>\n      <td>[True, False, False]</td>\n      <td>[True, False, False]</td>\n      <td>[False, True]</td>\n    </tr>\n    <tr>\n      <th>19846</th>\n      <td>[False, True, False, False]</td>\n      <td>[True, False, False]</td>\n      <td>[False, False, True]</td>\n      <td>[False, True]</td>\n    </tr>\n    <tr>\n      <th>19847</th>\n      <td>[False, True, False, False]</td>\n      <td>[True, False, False]</td>\n      <td>[False, False, True]</td>\n      <td>[False, True]</td>\n    </tr>\n    <tr>\n      <th>19848</th>\n      <td>[False, True, False, False]</td>\n      <td>[True, False, False]</td>\n      <td>[True, False, False]</td>\n      <td>[False, True]</td>\n    </tr>\n    <tr>\n      <th>19849</th>\n      <td>[False, False, True, False]</td>\n      <td>[True, False, False]</td>\n      <td>[False, True, False]</td>\n      <td>[False, True]</td>\n    </tr>\n  </tbody>\n</table>\n<p>19850 rows × 4 columns</p>\n</div>"},"metadata":{}}],"execution_count":21},{"cell_type":"markdown","source":"train, val set가 준비되었다면 위에서 만든 SetenceTypeDataset에 dataframe, tokenizer, labels들을 넣어주고 SentenceTypeDataset, batch_size는 필수적으로 값을 정해서 DataLoader에 넣어준다. 위에서 잠깐 언급했듯이 DataLoader는 지정된 batch_size만큼 item들을 모델에 넘겨주어서 training 할 수 있게 해준다.\n\n\n\n여기서 shuffle는 item들을 랜덤하게 고른다는 의미고 num_workers는 설명을 봐도 잘 모르겠다.","metadata":{"id":"hetr05lzn0UH"}},{"cell_type":"code","source":"pd.DataFrame(train_labels).iloc[:, 1]","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":458},"id":"PY7R5epjELUA","executionInfo":{"status":"ok","timestamp":1733938880575,"user_tz":-540,"elapsed":9,"user":{"displayName":"이준희","userId":"15645433344491411224"}},"outputId":"00a83799-8cca-4319-ef53-d1e52477b730","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T11:10:30.759578Z","iopub.execute_input":"2024-12-12T11:10:30.760228Z","iopub.status.idle":"2024-12-12T11:10:30.803102Z","shell.execute_reply.started":"2024-12-12T11:10:30.760194Z","shell.execute_reply":"2024-12-12T11:10:30.802198Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"0        [True, False, False]\n1        [True, False, False]\n2        [True, False, False]\n3        [True, False, False]\n4        [True, False, False]\n                 ...         \n79391    [True, False, False]\n79392    [False, False, True]\n79393    [True, False, False]\n79394    [True, False, False]\n79395    [True, False, False]\nName: polarity, Length: 79396, dtype: object"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"train_dataloader = DataLoader(SentenceTypeDataset(train_tmp, tokenizer, train_labels), batch_size=CFG['BATCH_SIZE'], shuffle=True, num_workers=0) # num_workers: how many subprocesses to use for data loading\n\nval_dataloader = DataLoader(SentenceTypeDataset(val_tmp, tokenizer, val_labels), batch_size=CFG['BATCH_SIZE'], num_workers=0)","metadata":{"id":"LAOt7rVwn0UH","executionInfo":{"status":"ok","timestamp":1733938908610,"user_tz":-540,"elapsed":28043,"user":{"displayName":"이준희","userId":"15645433344491411224"}},"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T11:10:31.755635Z","iopub.execute_input":"2024-12-12T11:10:31.756202Z","iopub.status.idle":"2024-12-12T11:10:55.250484Z","shell.execute_reply.started":"2024-12-12T11:10:31.756171Z","shell.execute_reply":"2024-12-12T11:10:55.249795Z"}},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":"그 다음으로는 base_model (klue를 이용한 pretrained_model)을 기반으로해서 SentenceClassifier를 불러준다.","metadata":{"id":"RHZOnSRnn0UH"}},{"cell_type":"code","source":"model = SentenceClassifier(base_model)","metadata":{"id":"mXHw1x46n0UH","executionInfo":{"status":"ok","timestamp":1733938908611,"user_tz":-540,"elapsed":12,"user":{"displayName":"이준희","userId":"15645433344491411224"}},"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T11:15:22.583382Z","iopub.execute_input":"2024-12-12T11:15:22.584030Z","iopub.status.idle":"2024-12-12T11:15:22.595813Z","shell.execute_reply.started":"2024-12-12T11:15:22.583983Z","shell.execute_reply":"2024-12-12T11:15:22.595052Z"}},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":"그리고 이제서야 training을 할 수 있는 상태에 온 것이다.\n\n\n\n위에서 만든 sentence_train function에 필요한 파라미터들을 보내주어서 training을 시작해준다.\n\n\n\n(위에서 말했듯이 f1을 계산 안하고 accuracy를 그대로 남겨주었기 때문에 accuracy는 계속 0이다.)","metadata":{"id":"RkZ_zwp2n0UH"}},{"cell_type":"code","source":"print(len(train_dataloader.dataset))  # 데이터셋 크기 확인\n\nprint(len(val_dataloader.dataset))    # 데이터셋 크기 확인","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N20RYezTwgWr","executionInfo":{"status":"ok","timestamp":1733938908611,"user_tz":-540,"elapsed":10,"user":{"displayName":"이준희","userId":"15645433344491411224"}},"outputId":"36589142-8ceb-43e5-f823-58dc87cfa2dc","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T11:15:23.292194Z","iopub.execute_input":"2024-12-12T11:15:23.292521Z","iopub.status.idle":"2024-12-12T11:15:23.298972Z","shell.execute_reply.started":"2024-12-12T11:15:23.292493Z","shell.execute_reply":"2024-12-12T11:15:23.298121Z"}},"outputs":[{"name":"stdout","text":"79396\n19850\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"for batch in train_dataloader:\n\n    print('batch', batch)  # 데이터가 올바르게 로드되는지 확인\n\n    break","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-jFqx7qwwl9X","outputId":"f706f5e8-0236-4ecc-dbb8-9d1afb0c9b8c","executionInfo":{"status":"ok","timestamp":1733938908611,"user_tz":-540,"elapsed":8,"user":{"displayName":"이준희","userId":"15645433344491411224"}},"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T11:15:25.891034Z","iopub.execute_input":"2024-12-12T11:15:25.891361Z","iopub.status.idle":"2024-12-12T11:15:26.031643Z","shell.execute_reply.started":"2024-12-12T11:15:25.891334Z","shell.execute_reply":"2024-12-12T11:15:26.030690Z"}},"outputs":[{"name":"stdout","text":"batch [{'input_ids': tensor([[[    0,  3625,    23,  ...,     1,     1,     1]],\n\n        [[    0,     3, 26947,  ...,     1,     1,     1]],\n\n        [[    0,  6910,  2259,  ...,     1,     1,     1]],\n\n        ...,\n\n        [[    0, 11821,  6724,  ...,     1,     1,     1]],\n\n        [[    0, 25668,  2850,  ...,     1,     1,     1]],\n\n        [[    0,   170,  1583,  ...,     1,     1,     1]]]), 'token_type_ids': tensor([[[0, 0, 0,  ..., 0, 0, 0]],\n\n        [[0, 0, 0,  ..., 0, 0, 0]],\n\n        [[0, 0, 0,  ..., 0, 0, 0]],\n\n        ...,\n\n        [[0, 0, 0,  ..., 0, 0, 0]],\n\n        [[0, 0, 0,  ..., 0, 0, 0]],\n\n        [[0, 0, 0,  ..., 0, 0, 0]]]), 'attention_mask': tensor([[[1, 1, 1,  ..., 0, 0, 0]],\n\n        [[1, 1, 1,  ..., 0, 0, 0]],\n\n        [[1, 1, 1,  ..., 0, 0, 0]],\n\n        ...,\n\n        [[1, 1, 1,  ..., 0, 0, 0]],\n\n        [[1, 1, 1,  ..., 0, 0, 0]],\n\n        [[1, 1, 1,  ..., 0, 0, 0]]])}, tensor([[0., 1., 0., 0.],\n        [0., 1., 0., 0.],\n        [0., 0., 0., 1.],\n        [0., 1., 0., 0.],\n        [0., 1., 0., 0.],\n        [0., 1., 0., 0.],\n        [0., 1., 0., 0.],\n        [0., 1., 0., 0.],\n        [0., 1., 0., 0.],\n        [0., 0., 0., 1.],\n        [0., 1., 0., 0.],\n        [0., 1., 0., 0.],\n        [0., 1., 0., 0.],\n        [0., 1., 0., 0.],\n        [0., 0., 0., 1.],\n        [0., 1., 0., 0.],\n        [0., 1., 0., 0.],\n        [0., 1., 0., 0.],\n        [0., 1., 0., 0.],\n        [0., 1., 0., 0.],\n        [0., 1., 0., 0.],\n        [0., 1., 0., 0.],\n        [0., 1., 0., 0.],\n        [0., 0., 0., 1.],\n        [0., 1., 0., 0.],\n        [0., 1., 0., 0.],\n        [0., 0., 0., 1.],\n        [0., 1., 0., 0.],\n        [0., 0., 0., 1.],\n        [0., 1., 0., 0.],\n        [1., 0., 0., 0.],\n        [0., 1., 0., 0.]]), tensor([[1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [0., 0., 1.],\n        [1., 0., 0.],\n        [0., 0., 1.],\n        [0., 0., 1.],\n        [0., 0., 1.],\n        [1., 0., 0.]]), tensor([[1., 0., 0.],\n        [0., 0., 1.],\n        [0., 1., 0.],\n        [0., 0., 1.],\n        [0., 0., 1.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [0., 0., 1.],\n        [1., 0., 0.],\n        [0., 0., 1.],\n        [1., 0., 0.],\n        [0., 0., 1.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [0., 1., 0.],\n        [0., 0., 1.],\n        [1., 0., 0.],\n        [0., 0., 1.],\n        [0., 0., 1.],\n        [0., 0., 1.],\n        [1., 0., 0.],\n        [0., 0., 1.],\n        [0., 0., 1.],\n        [0., 0., 1.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [0., 0., 1.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [0., 0., 1.],\n        [1., 0., 0.]]), tensor([[0., 1.],\n        [0., 1.],\n        [0., 1.],\n        [0., 1.],\n        [0., 1.],\n        [0., 1.],\n        [0., 1.],\n        [0., 1.],\n        [0., 1.],\n        [0., 1.],\n        [0., 1.],\n        [0., 1.],\n        [0., 1.],\n        [0., 1.],\n        [0., 1.],\n        [0., 1.],\n        [0., 1.],\n        [0., 1.],\n        [0., 1.],\n        [0., 1.],\n        [0., 1.],\n        [0., 1.],\n        [0., 1.],\n        [0., 1.],\n        [0., 1.],\n        [0., 1.],\n        [0., 1.],\n        [0., 1.],\n        [0., 1.],\n        [0., 1.],\n        [1., 0.],\n        [0., 1.]])]\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"sentence_train(model, train_dataloader, val_dataloader, CFG['LEARNING_RATE'], CFG['EPOCHS'], 'kclue')","metadata":{"id":"IBmBdZSdn0UH","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0b02afbf-c7af-451a-c6a9-06b7182a8a5b","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T11:15:52.626696Z","iopub.execute_input":"2024-12-12T11:15:52.627072Z","iopub.status.idle":"2024-12-12T14:48:18.676358Z","shell.execute_reply.started":"2024-12-12T11:15:52.627040Z","shell.execute_reply":"2024-12-12T14:48:18.675420Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 2482/2482 [09:45<00:00,  4.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"[1 1 1 ... 1 1 1]\n[1 1 1 ... 1 1 1]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 621/621 [00:47<00:00, 13.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"[1 1 1 ... 1 1 2]\n[1 1 1 ... 1 1 3]\nEpochs: 1 | Train Loss:  0.822 | Train F1 Score:  0.786 | Val Loss:  0.772 | Val F1 Score:  0.823\nSaved model\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2482/2482 [09:50<00:00,  4.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"[3 3 1 ... 1 1 0]\n[1 1 1 ... 1 1 0]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 621/621 [00:47<00:00, 13.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"[1 1 1 ... 1 1 2]\n[1 1 1 ... 1 1 1]\nEpochs: 2 | Train Loss:  0.740 | Train F1 Score:  0.815 | Val Loss:  0.705 | Val F1 Score:  0.838\nSaved model\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2482/2482 [09:50<00:00,  4.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"[0 1 1 ... 3 3 1]\n[0 1 1 ... 1 1 1]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 621/621 [00:47<00:00, 13.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"[1 1 1 ... 1 1 2]\n[1 1 1 ... 1 1 1]\nEpochs: 3 | Train Loss:  0.687 | Train F1 Score:  0.828 | Val Loss:  0.662 | Val F1 Score:  0.845\nSaved model\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2482/2482 [09:50<00:00,  4.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"[1 1 1 ... 1 1 1]\n[1 1 1 ... 1 1 1]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 621/621 [00:47<00:00, 13.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"[1 1 1 ... 1 1 2]\n[1 1 1 ... 1 1 1]\nEpochs: 4 | Train Loss:  0.652 | Train F1 Score:  0.845 | Val Loss:  0.635 | Val F1 Score:  0.866\nSaved model\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2482/2482 [09:49<00:00,  4.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"[1 1 3 ... 1 2 1]\n[1 1 1 ... 1 1 1]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 621/621 [00:46<00:00, 13.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"[1 1 1 ... 1 1 2]\n[1 1 1 ... 1 1 1]\nEpochs: 5 | Train Loss:  0.628 | Train F1 Score:  0.884 | Val Loss:  0.614 | Val F1 Score:  0.922\nSaved model\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2482/2482 [09:48<00:00,  4.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"[1 1 1 ... 1 1 1]\n[1 1 1 ... 1 1 1]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 621/621 [00:47<00:00, 13.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"[1 1 1 ... 1 1 2]\n[1 1 1 ... 1 1 1]\nEpochs: 6 | Train Loss:  0.610 | Train F1 Score:  0.927 | Val Loss:  0.601 | Val F1 Score:  0.942\nSaved model\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2482/2482 [09:48<00:00,  4.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"[1 1 1 ... 1 1 3]\n[1 1 1 ... 1 1 3]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 621/621 [00:46<00:00, 13.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"[1 1 1 ... 1 1 2]\n[1 1 1 ... 1 1 1]\nEpochs: 7 | Train Loss:  0.597 | Train F1 Score:  0.941 | Val Loss:  0.590 | Val F1 Score:  0.949\nSaved model\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2482/2482 [09:47<00:00,  4.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"[1 1 1 ... 1 1 1]\n[3 1 1 ... 1 1 1]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 621/621 [00:46<00:00, 13.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"[1 1 1 ... 1 1 2]\n[1 1 1 ... 1 1 1]\nEpochs: 8 | Train Loss:  0.588 | Train F1 Score:  0.951 | Val Loss:  0.582 | Val F1 Score:  0.955\nSaved model\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2482/2482 [09:48<00:00,  4.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"[3 1 3 ... 1 1 1]\n[3 1 3 ... 1 1 1]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 621/621 [00:46<00:00, 13.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"[1 1 1 ... 1 1 2]\n[1 1 1 ... 1 1 1]\nEpochs: 9 | Train Loss:  0.581 | Train F1 Score:  0.958 | Val Loss:  0.576 | Val F1 Score:  0.963\nSaved model\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2482/2482 [09:48<00:00,  4.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"[3 1 1 ... 1 1 1]\n[3 1 1 ... 1 1 1]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 621/621 [00:46<00:00, 13.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"[1 1 1 ... 1 1 2]\n[1 1 1 ... 1 1 2]\nEpochs: 10 | Train Loss:  0.576 | Train F1 Score:  0.964 | Val Loss:  0.572 | Val F1 Score:  0.966\nSaved model\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2482/2482 [09:48<00:00,  4.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"[1 3 3 ... 1 1 1]\n[1 1 3 ... 1 1 1]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 621/621 [00:46<00:00, 13.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"[1 1 1 ... 1 1 2]\n[1 1 1 ... 1 1 2]\nEpochs: 11 | Train Loss:  0.572 | Train F1 Score:  0.968 | Val Loss:  0.569 | Val F1 Score:  0.971\nSaved model\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2482/2482 [09:48<00:00,  4.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"[1 1 3 ... 1 1 1]\n[1 1 3 ... 1 1 1]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 621/621 [00:47<00:00, 13.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"[1 1 1 ... 1 1 2]\n[1 1 1 ... 1 1 2]\nEpochs: 12 | Train Loss:  0.569 | Train F1 Score:  0.972 | Val Loss:  0.566 | Val F1 Score:  0.972\nSaved model\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2482/2482 [09:49<00:00,  4.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"[1 1 1 ... 2 1 1]\n[1 1 1 ... 2 1 1]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 621/621 [00:47<00:00, 13.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"[1 1 1 ... 1 1 2]\n[1 1 1 ... 1 1 2]\nEpochs: 13 | Train Loss:  0.566 | Train F1 Score:  0.974 | Val Loss:  0.564 | Val F1 Score:  0.973\nSaved model\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2482/2482 [09:52<00:00,  4.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"[1 1 1 ... 1 1 1]\n[1 1 1 ... 1 1 1]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 621/621 [00:47<00:00, 13.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"[1 1 1 ... 1 1 2]\n[1 1 1 ... 1 1 2]\nEpochs: 14 | Train Loss:  0.564 | Train F1 Score:  0.975 | Val Loss:  0.563 | Val F1 Score:  0.973\nSaved model\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2482/2482 [09:51<00:00,  4.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"[1 1 1 ... 0 1 1]\n[1 1 1 ... 0 1 1]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 621/621 [00:47<00:00, 13.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"[1 1 1 ... 1 1 2]\n[1 1 1 ... 1 1 2]\nEpochs: 15 | Train Loss:  0.563 | Train F1 Score:  0.976 | Val Loss:  0.562 | Val F1 Score:  0.975\nSaved model\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2482/2482 [09:50<00:00,  4.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"[1 0 1 ... 1 1 1]\n[1 0 1 ... 1 1 1]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 621/621 [00:47<00:00, 13.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"[1 1 1 ... 1 1 2]\n[1 1 1 ... 1 1 2]\nEpochs: 16 | Train Loss:  0.561 | Train F1 Score:  0.976 | Val Loss:  0.560 | Val F1 Score:  0.976\nSaved model\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2482/2482 [09:50<00:00,  4.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"[1 3 1 ... 1 3 0]\n[1 3 1 ... 1 3 0]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 621/621 [00:47<00:00, 13.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"[1 1 1 ... 1 1 2]\n[1 1 1 ... 1 1 2]\nEpochs: 17 | Train Loss:  0.560 | Train F1 Score:  0.977 | Val Loss:  0.560 | Val F1 Score:  0.975\nSaved model\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2482/2482 [09:53<00:00,  4.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"[2 1 1 ... 3 1 1]\n[2 1 1 ... 1 1 1]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 621/621 [00:47<00:00, 13.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"[1 1 1 ... 1 1 2]\n[1 1 1 ... 1 1 2]\nEpochs: 18 | Train Loss:  0.559 | Train F1 Score:  0.978 | Val Loss:  0.559 | Val F1 Score:  0.976\nSaved model\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2482/2482 [09:49<00:00,  4.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"[1 1 1 ... 1 1 1]\n[1 1 1 ... 1 1 1]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 621/621 [00:46<00:00, 13.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"[1 1 1 ... 1 1 2]\n[1 1 1 ... 1 1 2]\nEpochs: 19 | Train Loss:  0.559 | Train F1 Score:  0.978 | Val Loss:  0.558 | Val F1 Score:  0.977\nSaved model\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2482/2482 [09:49<00:00,  4.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"[1 3 1 ... 1 1 1]\n[1 3 1 ... 1 1 1]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 621/621 [00:47<00:00, 13.18it/s]","output_type":"stream"},{"name":"stdout","text":"[1 1 1 ... 1 1 2]\n[1 1 1 ... 1 1 2]\nEpochs: 20 | Train Loss:  0.558 | Train F1 Score:  0.979 | Val Loss:  0.559 | Val F1 Score:  0.977\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":28},{"cell_type":"markdown","source":"training이 끝났으면 test data를 이용해 예측을 해야되는데 이때 방법은 validation때와 비슷하다. 따라서, 설명은 생략하겠습니다.","metadata":{"id":"Y4QvLgFUn0UI"}},{"cell_type":"code","source":"def get_type_predictions(model, loader):\n\n\n\n    device = torch.device('cuda')\n\n    model = model.to(device)\n\n\n\n    type_probs, polarity_probs, tense_probs, clarity_probs = [], [], [], []\n\n    with torch.no_grad():\n\n        model.eval()\n\n        for data_input, _, _, _, _ in tqdm(loader):\n\n            attention_mask = data_input['attention_mask'].to(device)\n\n            input_ids = data_input['input_ids'].squeeze(1).to(device)\n\n\n\n\n\n            type_output, polarity_output, tense_output, clarity_output = model(input_ids, attention_mask)\n\n            type_probs.append(type_output)\n\n            polarity_probs.append(polarity_output)\n\n            tense_probs.append(tense_output)\n\n            clarity_probs.append(clarity_output)\n\n\n\n    return torch.cat(type_probs).cpu().detach().numpy(), torch.cat(polarity_probs).cpu().detach().numpy(), torch.cat(tense_probs).cpu().detach().numpy(), torch.cat(clarity_probs).cpu().detach().numpy()","metadata":{"id":"giX1utUYn0UI","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T14:48:48.181232Z","iopub.execute_input":"2024-12-12T14:48:48.181560Z","iopub.status.idle":"2024-12-12T14:48:48.188233Z","shell.execute_reply.started":"2024-12-12T14:48:48.181532Z","shell.execute_reply":"2024-12-12T14:48:48.187265Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"model = torch.load(\"model/kclue.pt\")\n\ntest_dataloader = DataLoader(SentenceTypeDataset(test, tokenizer), batch_size=CFG['BATCH_SIZE'], shuffle=False)","metadata":{"id":"fkMqTaDHn0UI","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T14:48:48.948844Z","iopub.execute_input":"2024-12-12T14:48:48.949532Z","iopub.status.idle":"2024-12-12T14:48:50.801218Z","shell.execute_reply.started":"2024-12-12T14:48:48.949500Z","shell.execute_reply":"2024-12-12T14:48:50.800425Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_23/2629143655.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model = torch.load(\"model/kclue.pt\")\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"#val_pred_type, val_pred_polarity, val_pred_tense, val_pred_certainty = get_type_predictions(model, val_dataloader)\n\n\n\n#val_type = ['대화형' if i==0 else '사실형' if i==1 else '예측형' if i==2 else '추론형' for i in [np.argmax(p) for p in val_pred_type]]\n\n#val_polarity = ['긍정' if i==0 else '미정' if i==1 else '부정' for i in [np.argmax(p) for p in val_pred_polarity]]\n\n#val_type = ['과거' if i==0 else '미래' if i==1 else '현재' for i in [np.argmax(p) for p in val_pred_tense]]\n\n#val_type = ['불확실' if i==0 else '확실' for i in [np.argmax(p) for p in val_pred_certainty]]","metadata":{"id":"Z04H4Qpgn0UI","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T14:48:53.567196Z","iopub.execute_input":"2024-12-12T14:48:53.567533Z","iopub.status.idle":"2024-12-12T14:48:53.572198Z","shell.execute_reply.started":"2024-12-12T14:48:53.567505Z","shell.execute_reply":"2024-12-12T14:48:53.571209Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"test_pred_type, test_pred_polarity, test_pred_tense, test_pred_certainty = get_type_predictions(model, test_dataloader)","metadata":{"id":"gseX3IdOn0UI","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T14:48:54.963055Z","iopub.execute_input":"2024-12-12T14:48:54.963356Z","iopub.status.idle":"2024-12-12T14:49:11.387152Z","shell.execute_reply.started":"2024-12-12T14:48:54.963331Z","shell.execute_reply":"2024-12-12T14:49:11.386197Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 222/222 [00:16<00:00, 13.56it/s]\n","output_type":"stream"}],"execution_count":34},{"cell_type":"markdown","source":"여기서 잠깐 test_pred_tense가 어떻게 생겼는지 살펴보면","metadata":{"id":"-xa-6c1gn0UM"}},{"cell_type":"code","source":"test_pred_tense","metadata":{"id":"lDXSTVJLn0UM","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T14:49:19.671271Z","iopub.execute_input":"2024-12-12T14:49:19.671943Z","iopub.status.idle":"2024-12-12T14:49:19.678144Z","shell.execute_reply.started":"2024-12-12T14:49:19.671910Z","shell.execute_reply":"2024-12-12T14:49:19.677248Z"}},"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"array([[8.8705689e-05, 1.2758546e-04, 9.9978381e-01],\n       [8.7229186e-05, 1.2457263e-04, 9.9978822e-01],\n       [9.9982470e-01, 6.3605949e-05, 1.1173662e-04],\n       ...,\n       [3.3157936e-03, 9.9397248e-01, 2.7117103e-03],\n       [2.0267006e-02, 9.3503118e-01, 4.4701785e-02],\n       [9.9982858e-01, 6.2598578e-05, 1.0876919e-04]], dtype=float32)"},"metadata":{}}],"execution_count":35},{"cell_type":"markdown","source":"위에 보이는 것과 같이 tense에는 3개의 타입이 있으므로 3개의 컬럼들을 볼 수 있다. 그리고 각 컬럼에 해당될 확률이 어느정도인지 저장되어 있는 형태이다. 이때 같은 row에 위치한 값들을 더해보면","metadata":{"id":"g_ZzNnAPn0UM"}},{"cell_type":"code","source":"sum(test_pred_tense[0])","metadata":{"id":"z-XjnLZ6n0UM","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T14:49:21.151411Z","iopub.execute_input":"2024-12-12T14:49:21.151747Z","iopub.status.idle":"2024-12-12T14:49:21.158044Z","shell.execute_reply.started":"2024-12-12T14:49:21.151719Z","shell.execute_reply":"2024-12-12T14:49:21.157066Z"}},"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"1.0000001051012077"},"metadata":{}}],"execution_count":36},{"cell_type":"markdown","source":"1인것을 알 수 있다. 위에 softmax에서 설명한 그대로이다.\n\n\n\n따라서, 이제 이 값들을 np.argmax()를 통해서 어느 인덱스에 최고 값이 있는지 알아보고 그 인덱스에 맞춰서 맞는 label로 변형해줘야 한다.\n\n그 후 저장하면 제출할 수 있는 파일이 만들어진다.","metadata":{"id":"XYJCx-ren0UM"}},{"cell_type":"code","source":"test_type = ['대화형' if i==0 else '사실형' if i==1 else '예측형' if i==2 else '추론형' for i in [np.argmax(p) for p in test_pred_type]]\n\ntest_polarity = ['긍정' if i==0 else '미정' if i==1 else '부정' for i in [np.argmax(p) for p in test_pred_polarity]]\n\ntest_tense = ['과거' if i==0 else '미래' if i==1 else '현재' for i in [np.argmax(p) for p in test_pred_tense]]\n\ntest_certainty = ['불확실' if i==0 else '확실' for i in [np.argmax(p) for p in test_pred_certainty]]","metadata":{"id":"uyym_mHNn0UM","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T14:49:23.613412Z","iopub.execute_input":"2024-12-12T14:49:23.613787Z","iopub.status.idle":"2024-12-12T14:49:23.670600Z","shell.execute_reply.started":"2024-12-12T14:49:23.613755Z","shell.execute_reply":"2024-12-12T14:49:23.669678Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"label_sum = []\n\nfor i in range(len(test_type)):\n\n    label_sum.append(f'{test_type[i]}-{test_polarity[i]}-{test_tense[i]}-{test_certainty[i]}')\n\nos.makedirs('submission', exist_ok=True)\n\n\n\nsubmission['label'] = label_sum\n\nsubmission.to_csv('submission/klue1.csv', index=False)","metadata":{"id":"otzbsMVqn0UM","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T14:49:24.523656Z","iopub.execute_input":"2024-12-12T14:49:24.524434Z","iopub.status.idle":"2024-12-12T14:49:24.551301Z","shell.execute_reply.started":"2024-12-12T14:49:24.524395Z","shell.execute_reply":"2024-12-12T14:49:24.550584Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"submission","metadata":{"id":"kiU6ya37n0UN","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T14:49:25.423574Z","iopub.execute_input":"2024-12-12T14:49:25.423876Z","iopub.status.idle":"2024-12-12T14:49:25.433922Z","shell.execute_reply.started":"2024-12-12T14:49:25.423850Z","shell.execute_reply":"2024-12-12T14:49:25.432931Z"}},"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"             ID         label\n0     TEST_0000  사실형-긍정-현재-확실\n1     TEST_0001  사실형-긍정-현재-확실\n2     TEST_0002  사실형-긍정-과거-확실\n3     TEST_0003  사실형-긍정-과거-확실\n4     TEST_0004  사실형-긍정-과거-확실\n...         ...           ...\n7085  TEST_7085  사실형-긍정-현재-확실\n7086  TEST_7086  추론형-긍정-현재-확실\n7087  TEST_7087  사실형-긍정-미래-확실\n7088  TEST_7088  추론형-긍정-미래-확실\n7089  TEST_7089  사실형-긍정-과거-확실\n\n[7090 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>TEST_0000</td>\n      <td>사실형-긍정-현재-확실</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>TEST_0001</td>\n      <td>사실형-긍정-현재-확실</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>TEST_0002</td>\n      <td>사실형-긍정-과거-확실</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>TEST_0003</td>\n      <td>사실형-긍정-과거-확실</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>TEST_0004</td>\n      <td>사실형-긍정-과거-확실</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7085</th>\n      <td>TEST_7085</td>\n      <td>사실형-긍정-현재-확실</td>\n    </tr>\n    <tr>\n      <th>7086</th>\n      <td>TEST_7086</td>\n      <td>추론형-긍정-현재-확실</td>\n    </tr>\n    <tr>\n      <th>7087</th>\n      <td>TEST_7087</td>\n      <td>사실형-긍정-미래-확실</td>\n    </tr>\n    <tr>\n      <th>7088</th>\n      <td>TEST_7088</td>\n      <td>추론형-긍정-미래-확실</td>\n    </tr>\n    <tr>\n      <th>7089</th>\n      <td>TEST_7089</td>\n      <td>사실형-긍정-과거-확실</td>\n    </tr>\n  </tbody>\n</table>\n<p>7090 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"import joblib\n\ntorch.save(model.state_dict(), \"klue_state_dict.pth\")\n\njoblib.dump(\"klue_state_dict.pth\", './klue_model.pkl')","metadata":{"id":"eAB-AjC7cV-z","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T14:48:18.704563Z","iopub.status.idle":"2024-12-12T14:48:18.704885Z","shell.execute_reply.started":"2024-12-12T14:48:18.704732Z","shell.execute_reply":"2024-12-12T14:48:18.704749Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\n\nimport joblib\n\n\n\n# joblib으로 압축된 state_dict 파일을 불러옴\n\nstate_dict_path = joblib.load(\"./klue_model.pkl\")\n\nmodel.load_state_dict(torch.load(state_dict_path))\n\nmodel.eval()","metadata":{"id":"VoRvWkbk2jg_","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T14:48:18.706400Z","iopub.status.idle":"2024-12-12T14:48:18.706721Z","shell.execute_reply.started":"2024-12-12T14:48:18.706554Z","shell.execute_reply":"2024-12-12T14:48:18.706569Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for name, param in model.named_parameters():\n\n    print(f\"{name}: {param[0]}\")\n\n    break  # 첫 번째 파라미터만 출력","metadata":{"id":"tPbwZ0cj2lo7","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T14:48:18.707761Z","iopub.status.idle":"2024-12-12T14:48:18.708085Z","shell.execute_reply.started":"2024-12-12T14:48:18.707900Z","shell.execute_reply":"2024-12-12T14:48:18.707915Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"궁금한 부분이나 조언이 있다면 댓글에 남겨주세요","metadata":{"id":"e4K-Ds4Yn0UN"}}]}